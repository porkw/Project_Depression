{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,random_split\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from itertools import chain\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\" #英文pretrain(不區分大小寫)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict size 21128\n",
      "token               index          \n",
      "-------------------------\n",
      "adam                11194\n",
      "##輓                 19793\n",
      "##硅                 17852\n",
      "cut                 12322\n",
      "##≧                 13548\n",
      "##reen              10902\n",
      "癒                    4618\n",
      "[unused3]               3\n",
      "待                    2521\n",
      "e                     147\n"
     ]
    }
   ],
   "source": [
    "# get pre-train tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "vocab = tokenizer.vocab\n",
    "print(\"dict size\", len(vocab))\n",
    "\n",
    "# see some token and index mapping\n",
    "import random\n",
    "random_tokens = random.sample(list(vocab), 10)\n",
    "random_ids = [vocab[t] for t in random_tokens]\n",
    "\n",
    "print(\"{0:20}{1:15}\".format(\"token\", \"index\"))\n",
    "print(\"-\" * 25)\n",
    "for t, id in zip(random_tokens, random_ids): #隨便看幾個字\n",
    "    print(\"{0:15}{1:10}\".format(t, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('validation.csv')\n",
    "total = pd.concat([train, val])\n",
    "total = total.reset_index(drop=True)\n",
    "total_0 = total[total[\"Label\"] == 0]\n",
    "total_1 = total[total[\"Label\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label_1\n",
    "num_1 = total_1.shape[0]\n",
    "random_1 = random.sample(range(num_1), num_1)\n",
    "train_1 = total_1.iloc[random_1[:108]]\n",
    "test_1 = total_1.iloc[random_1[108:135]]\n",
    "# Label_0\n",
    "num_0 = total_0.shape[0]\n",
    "random_0 = random.sample(range(num_0), num_0)\n",
    "train_0 = total_0.iloc[random_0[:400]]\n",
    "test_0 = total_0.iloc[random_0[400:500]]\n",
    "# train_val_1\n",
    "train_val_1 = train_1.shape[0]\n",
    "random_train_val = random.sample(range(train_val_1), train_val_1)\n",
    "train__1 = train_1.iloc[random_train_val[:97]]\n",
    "val_1 = train_1.iloc[random_train_val[97:108]]\n",
    "# train_val_0\n",
    "train_val_0 = train_0.shape[0]\n",
    "random_train_val = random.sample(range(train_val_0), train_val_0)\n",
    "train__0 = train_0.iloc[random_train_val[:360]]\n",
    "val_0 = train_0.iloc[random_train_val[360:400]]\n",
    "# train_val\n",
    "train = pd.concat([train__1, train__0])\n",
    "train = train.reset_index(drop=True)\n",
    "val = pd.concat([val_1, val_0])\n",
    "val = val.reset_index(drop=True)\n",
    "# test\n",
    "test = pd.concat([test_1, test_0])\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def toList(data):\n",
    "    df = []\n",
    "    for j in range(len(data)):\n",
    "        index = []\n",
    "        index.append(data.iloc[j]['Content'])\n",
    "        index.append(data.iloc[j]['Label'])\n",
    "        df.append(index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['還有一天好怕好怕搬家也好怕好怕活著好怕也好怕死十年了一直反覆發作我好難受新聞常常有人一下就消失了應該消失的是我才對吧...為什麼想死的人死不了不想死的人老天卻要帶走他們呢總有一天我會好，一直這樣騙自己--謝謝過的不好',\n",
       "  1],\n",
       " ['把自己關在一片漆黑的房間裡 全身沒有力氣 忍受不了的痛苦只能靠哭泣和尖叫發洩夢裡跟現實好像也沒有差別 一樣像瘋子一樣發洩(只是我有力氣打人了:)) 這樣的情況真的連要結束自己都不容易我不知道悲傷從何而來 我覺得我就像一具有意識的屍體 我真希望現在立刻有人能結束我的意識--',\n",
       "  1],\n",
       " ['(第一人稱視角，)媽媽跟爸爸從我出生就感情不好 所以國小時離婚了我喜歡媽媽 不喜歡爸爸但我們(姐姐)是跟爸爸住這個結果不是我能選擇的\"我並不幸福 但也不可憐在那之後各種爭執..心酸除了姐姐 這個家很安',\n",
       "  1],\n",
       " ['轉頭就走渣男果然是不會真心付出的我好想要去死我真的只在意我媽難怪 我姐難過我爸我不在意我現在好痛苦想跟你說我只是鬧脾氣 我還是喜歡你但來不及了而且我知道你一點也不好是我一廂情願很久沒割腕了https://i.imgur.com/cUyIwVY.jpg新的 好想吃了會死的藥喔--我被講得好難聽喔[氧氣] 請注意：s0XXX38e已婚還寄信https://www.ptt.cc/bbs/AllTogether/M.1589498591.A.B07.html全列入噁男封鎖名單：)也好我除了一開始氣頭上會回後來就算了 但還有人說我態度不值得同情...呵呵各種檢討我',\n",
       "  1],\n",
       " ['我大概只能住三樓以下剛剛在9樓嘗試找窗戶開口可惜一個都沒有想像躍身的瞬間腿軟了以前住6樓常常在想但6樓應該很難-----Sent from JPTT on my iPhone--',\n",
       "  1],\n",
       " ['各位晚安本版po,小魯大約1年前的生了病（類似面部痙攣的）至今仍找不到原因跟確切的治療方式，主要是因為病痛（80%）+許多平常課業上的壓力（20%）搞到我現在常常覺得非常難受，曾去做網路上的憂鬱檢測是達標的，主要狀況有沒辦法專心做別的事，常掉淚，對任何事提不起興趣，很想去死等等。 但是像我這樣很明顯知道自己痛苦的原因，而且只要身體沒發作我的心情就會好很多，但發作了就會變得想剛剛那樣負能量爆棚，是適合去身心科做檢查的嗎？請版友們給我點建議 謝謝大家--',\n",
       "  1],\n",
       " ['又開始失眠。尿道炎也又復發了。深刻的覺得自己沒用。藥也吃回fm2，明明給自己的底線是不要再吃回fm2的。人生好難，渾渾噩噩的走過每一個想離開的時候。但什麼時候會走不下去呢，我也不曉得。想像一隻貓，躲起來，靜靜的離開。--什麼遺失物XD',\n",
       "  1],\n",
       " ['人在最脆弱的時候，被關心了就一股腦的吐露實情，我跟姐姐講了我今年的計畫，打算把財產結算，好好與人告別，做最後能做的好事，把東西給需要的人結束與人的緣分，我很感謝曾經對我好的人，是我自己無法戰勝這一圈一圈的心病，我只是不想困住了，下輩子我希望能當空氣、泥土。一切一切都很感激所有曾經的痛都不再痛消失了消失了最簡單的儀式不用燒香不用金紙不用念經我的都是我的家人的，隨便怎麼分配都好，因為我知道你們對我的感情是真的，我不後悔，不用急救不用救我願這個宇宙這個世界美好，讓其他人都可以有希望--',\n",
       "  1],\n",
       " ['一下班強迫症跟憂鬱又大發作明明只是第二天上班步調好快我跟不上根本也都沒準時下班又沾東沾西要死了又瘋狂洗手洗東西洗不完的自己即使搬出去租屋但根本沒有經濟來源媽媽又勸不聽簽約了原本住娘家娘家也強迫我們要整個重新裝潢還給他們新租屋處又什麼都沒有什麼也要買這樣根本是裝潢兩個家一想到壓力就爆炸又開始瘋狂洗手洗東西停不下來好想死我好難受我好累上吊預先打好的結又不知道去哪了乾脆讓這變成凶宅反正這跟鬼一樣每天只會吵架跟酸的家根本不是人住的家裡三個全都因此憂鬱症好想死，為什麼這麼累連死也做不到的我--',\n",
       "  1],\n",
       " ['好不容易可以開開手機看看訊息還是很討厭手機響跟按電鈴想畫畫跟看書但都沒有力做不到好累莫名的無力跟痛讓我覺得好煩自殺意念比較少了但我根本是廢物--',\n",
       "  1],\n",
       " ['健身房我照去但我心已死每天都想吞藥自殺可惜藥都太弱了我昨天本來想割腕但我真的不捨得我媽就只是這原因放過我好嗎這個世界--p大 我覺得人生好難只有死可以逃避 為什麼我媽不要我死他希望我痛苦嗎',\n",
       "  1],\n",
       " ['我想要自殺，我是生下來就有障礙過得比其他人辛苦活不下去了，不知道有沒有人想過自殺，目前決定其摩托車不帶安全帽加速撞公車', 1],\n",
       " ['我覺得我做人很失敗明明知道這樣是不對的但還是會去做越來越無法控制自己的情緒常常把氣出在身邊的人身上或許他們做的也不夠好但我仍會不由自主把事情放大一直想尋找一個發洩的出口氣發出來又會有愧疚感悲哀的人生沒有一件事是順利的好想什麼都不管的登出天天都想吐--',\n",
       "  1],\n",
       " ['我目前只想到一個就是燒炭但是我又不想讓我家變凶宅所以地點蠻難選擇的希望有人提供那種自殺不會痛又簡單的方法對了，別提吃安眠藥這種沒用的方法其實我也有想過被車撞，不過怕車子速度不快再來是跳樓怕我家社區大樓',\n",
       "  1],\n",
       " ['軟爛的身軀沒辦法再容納更高純度的傷悲。時光暴雨如樁，心裡累長的青苔無能被日光寵幸，只有迤邐著的記憶與濕氣。好恨自己好痛苦好想死可是好喜歡你--我只想健健康康地愛人，健健康康地被愛。--',\n",
       "  1],\n",
       " ['之前有發過一篇恐怖的松德住院經驗，當時發文的我21歲，現在已經23歲了。我還活著，要感謝的人大概可以另發一篇文寫滿滿。而且算到現在我已經住了10次院，松德、台大各五次，想問經驗可以問我（什麼）。我就讀的大學是台北11x，大四開始生病，開始被老師當掉好幾門課，開始瘋狂的住院，完全無法顧及學校課業。最後結果當然是延畢，把診斷證明一一寄送到老師信箱，解釋我為何要住院而且一住就至少一個月。佛心老師看我已經大五了，大多讓我寫報告或用其他方式代替各種上台報告、小組活動、期中期末考等等等。在各位老師的放水與愛心下，最後放棄了一個快修完的學程，延畢一年後終於拿到畢業證書。這個過程難以詳述的千辛萬苦，只有醫生最知道。所以當週回診時抱著畢業證書，遞給醫生，那個氛圍簡直可以含淚相擁了（好啦沒有）。所以我畢業了！住台大的某一次，正是研究所的考季。我天天趴在桌上讀書寫筆記，日復一日，搞到醫生跟護理師都說你可以好好休息嗎？那一次住院為了考試出院了。最後我考上了另一間台北的11x。松德的醫生、台大的醫生、我的心理師，這三個人的反應都是我的天啊，你到底做了什麼。所以我有研究所可以唸了！（另一個好消息）這個病程呢，說辛苦是辛苦。幻覺、解離等等各種都經歷過。我對藥物的反應又不好（我真的曾經吃到一天900mg的思樂康，還沒聽過比我更厲害的，而且我當時的身高體重頂多只有166/47，我可憐的腎啊），rTMS、電療這些非藥物治療，也全都做過一輪了，醫生也覺得棘手，調不出一個好的組合。現在同時用四種抗憂鬱劑，還吃一個副作用非常阿雜的可致律，真的是很該減藥，但醫生遲遲沒下手就是了。辛苦之外，我還要抱著PTSD活著，時不時想要自殘自殺，就要想我一週有兩個醫生的回診，我要撐住，很快就可以見到醫生了。各種藥物副作用、血清素症候群同時在我的身體發作，呼吸困難、視力模糊，手抖到無法自己剪指甲，我還得跟這些症狀和平共處，因為藥還是得吃。往後想以前的事會非常痛苦，往前想未來的事會非常恐懼。我最喜歡的住院醫師跟我說過，你只是會讀書而已，你的情緒感知能力真的很差啊。想想也是，我在同學面前都笑得那麼快樂，化妝拍照就像個普通的大學女生，但背後那些混亂我根本不知道如何處理。讀書有什麼重要的，這才是我一生的功課吧，至少現在的我已經開始要著手行動了。廢話一堆，真的有板友會看到這裡嗎XDD最後還是希望大家一起加油啦，雖然我每天也是過著怕得要死或真的很想死的生活，但是為了那些很愛我們的人，想死跑急診，努力活下去吧！--',\n",
       "  1],\n",
       " ['老實說，這兩天我都無法感覺到L的存在，我拼命告訴自己他在、他有在聽，自顧自地說，所以其實我很驚訝L昨天說他很想知道我瘋狂想念Y時在想什麼。只是因為自己情緒狀況的不穩定，（可能是經前）我今天完全感受不到L就在我身後，治療中我也從未冷靜下來，思緒非常混亂。於是五十分鐘就這樣過去了，我很不滿地離開治療室，但心中清楚L沒有錯，任性的是我。Y是你心中減不掉的重量。L如此說道。我知道Y對我一直就是治療師對個案的態度，可是我對他移情，很深很深，直到他離開兩年多以後，依然牢牢存在我心中。我希望可以有個願意像Y一樣待我好、珍惜我的男人，然而我母胎單身，現在又沒有工作、當個不知道在幹嘛的全職考生、說身材沒身材的，怎麼會有人願意愛我？我都不愛自己了。P教練跟我說過如果一個男人是因為你的外表而喜歡你，那我就得要很小心，擔心他是否因為我的外表不在而移情別戀。可是我大學男同學說男人第一眼當然是看外表...但我真的沒有QAQ狀況非常糟，今晚打算多吃半顆導美睡和美舒鬱，才能早點入睡又睡得久。活著有什麼意義嗎？死了才是真正的解脫~我不愛我自己，也不會有人願意愛我。--',\n",
       "  1],\n",
       " ['每天都很空洞不知道自己到底為什麼下班之後更是常常莫名想哭莫名的不想動莫名的一直自己掐住喉嚨到沒力掐到乾咳乾嘔好想用剪刀刺死自己刺脖子很深總有用吧好痛苦很想幫毛孩找個歸宿讓自己可以一走了之但毛孩也很老了一定沒有人要而且不知道會不會幸福才第三天就想辭職了把工作跟一切放掉存款應該還可以用到他們走的時候他們走了我就可以走了好想走--他們討厭抱抱QQ',\n",
       "  1],\n",
       " ['想請問各位如果不在租屋處自殺的話在哪執行會比較好呢雖然房東很煩又很貪小便宜、環境又爛但我也不想害那裡變凶宅萬一他跟我老爸討賠償更要不得在親人家很容易被發現目前想用上吊或跳樓離開上吊我想只有野外可行了吧',\n",
       "  1],\n",
       " ['（雷雨說不出口的沒有想活為什麼不能想死我好累想乾淨安心的離開卻找不到方法我好想走。--', 1],\n",
       " ['我恨憂鬱症我恨貼標籤我恨那些自以為憂鬱症的人我恨講憂鬱症幹話的人我恨我自己我想ㄙˇ！--', 1],\n",
       " ['半夜總是失眠，藥物好多呀······重度憂鬱症什麼時候好呀下週要進住宿舍半夜睡不著，會不會吵到別人會不會因為藥物又夢遊請大家不要批評責罵我只是很累但我還想活著不敢打1995或許我真的不該存在我想自殺，只是逃避',\n",
       "  1],\n",
       " ['她自己的情緒沒控制好，導致說出口的話傷到了我以致於我又發作的很想死一直說出這樣類似的話就是要她走著瞧，看會不會真的發生在恐嚇她要她見棺材她說她自己也不好過，不知為何會這樣妳不好受是妳自己造成的又不是我的錯而我會變成這樣都是你們父母害的看我這樣起笑，說對不起有屁用嗎事情一而再的發生，到底要折磨我幾次為何自己的人生這樣悲慘為何有人可以幸福真的很想死，只是從沒做過--',\n",
       "  1],\n",
       " ['#手機排版爛拍謝我是家裡的長子，從出生到現在我弟的待遇永遠比我好，糖果多買，飲料喝大杯......之類的我不知道我造了什麼孽，我覺得我一直都很乖，直到國小我受不了就開始學壞了。國小三年級爸媽離婚我跟爸',\n",
       "  1],\n",
       " ['後悔昨天沒有將刀刺進喉嚨痛恨自己的軟弱無力每次覺得好像好一點點馬上就又被排山倒海的自殺意念襲擊為什麼這麼痛看到新聞不幸死亡的人都好難過為什麼我不能代替他們呢受不了了每天的精神霸凌好累--來自家庭',\n",
       "  1],\n",
       " ['是不是得了重度憂鬱症 剩下來的下半輩子會一直跟著你都不會好了...我很懷疑自己 家庭雖然爸媽離婚但是爸爸還是對我很好家裡也不窮 我自己也沒有過的多差 自己也交了一個男朋友 說真的外表很像人生勝利組 但',\n",
       "  1],\n",
       " ['最近因為一些事情，憂鬱症又開始復發了，我想回去找醫生，這怕看到醫生又不知道講什麼，只能靜靜的坐在診間裡崩潰大哭，一直對我很好的那個人，突然消失了，當初為了他活下來，現在沒有他了，我是不是可以放下一切了',\n",
       "  1],\n",
       " ['本文原由美國《外交政策》（Foreign Policy）於2020年8月20日刊載，英文原文報導於此。經編輯同意授權，由原文作者翻譯為中文於關鍵評論網專欄發表。 「無兵可用、有兵誤用」的台灣國軍',\n",
       "  0],\n",
       " ['久違的接龍~（清喉嚨）今天是2020/8/7 14:29報復性睡覺……昨天從高雄回宜蘭 累翻天劈腿的人都給我去吃大便>_<！！氣 什麼乾姐啊……--',\n",
       "  0],\n",
       " ['昨天的狀況是什麼都對了，今天的狀況是什麼都不對。昨晚反覆作夢卻醒不來，在夢中極度焦躁，讓我五點醒來後，過了約兩三個小時又躺床睡了兩個小時，一整個就是很差的睡眠品質，躺在床上總是無比焦躁，考慮今晚睡期是不是吃顆長效Xanax看看是否有效？這週的飲食非常亂來，雖然總熱量沒有超過太多，但我吃了很多精緻食物，可是真正吃到時也不覺得特別美味:(星期一無意間翻起那本書後，雖然心中許多不懂可是也有很多想法，L說這是一種可以在「不知道」中待著而自由想像的能力，我並不確定自己是否如他所說真的有了這樣的能力，不過我的確認為就算對理論懵懵懂懂，還是可以勾引出許多想法的~畢竟整本書不是只有理論，也會有作者的臨床經驗，兩者搭配總能引發出一些想法，可是這些想法我只能對L說，朋友們沒人懂，家人也不懂，令人孤單:(大部分的人們都認為「要做些什麼」才是正確的，才是有認真努力著，但是我的經驗告訴我「過於著急要做些什麼結果可能不是自己要的。」可是我隱約知道朋友不認同我一直沒工作當靠爸族，只是我也付出照顧我爸情緒的代價才換來現在這種「有條件的自由」，然而朋友哪會懂？世人更不可能理解。人們總是一直要我盡快找份工作，我當然也想要有工作讓自己經濟自由，可是自己現在的狀況真的是做不到，但我不是因此就擺爛阿~我只是需要更多時間慢慢將事情一件件處理，但是朋友們不會理解。很累。就算真的和朋友有約，也是孤單的。--',\n",
       "  0],\n",
       " ['因為用pitt不知怎麼回文，直接另開一篇。贊安諾有減低煎熬感，但也無法完全趕跑。今天拿著醫師的診斷證明給學校，上面寫「為避免病情惡化至需要住院，強烈建議在家休養三至四個月為宜」，但主任看了，說先讓我請假三週；下午他上簽呈給校長，校長說只能請兩週。覺得很不爽，我臨時出狀況，對學生已經很抱歉了，只有兩週是要我過更焦慮的生活嗎？這種煎熬感、如坐針氈，只有箇中人才能體會，你當然也沒義務去了解。好累......--',\n",
       "  0],\n",
       " [': 標題: Re: [陰天] 久違的大焦慮: 時間: Thu Jun 4 18:41:35 2020: 推 lockinboy: 加油 06/04 19:07: 推 eternalfall: 非出勤日去繳回管理費，這就是出勤啊。光這一點就違 06/04 19:32: → eternalfall: 法了 06/04 19:32後來禮拜五保全公司派了另一個人來比較客氣一點，但還是笑裡藏刀，我對他依然沒有好感不過我跟他說假日出勤的事他雖然不甘不願還是有給我一小時的錢但是其他的事我必須站穩立場我告訴他，要我交保人資料前，必須把合約印一份給我（當然正本更好）他說是機密不能攜出我說是保人要求，不給就不保，這件事僵住另外我說簽約那天因為趕時間，我和另一位同事都沒有仔細看內容而你們當天接待我們的副課長，也沒有仔細說明班表只說是做一休一，但隱瞞了遇到周末要連上三天的事...等等反正我就是要咬緊這些事情，因為都是事實，我沒有捏造現在就是等6/21開會了反正最糟的情況，就是我也不做了我知道沒工作很可怕但是我也真的好久沒有比較長的休息了其實這不是甚麼好工作我一直沒法子下決心離開，就是怕離開這裡沒有下一個工作既然外在因素要推我一把也不見得是壞事--',\n",
       "  0],\n",
       " ['夢到一半生氣醒來很久沒想起的人。至今我仍然不知道最後他找了很好的星級餐廳原本的用意到底是什麼相信出發點不是壞的只是整個過程中對對方的眷戀消耗殆盡盛怒下我遲到許久 見面後怒氣不減反增最後不歡而散至今我沒有過一絲後悔因為當時的我不懂一昧忍耐到最後這樣的結果難以避免甚至連約定時都沒有意識到自己的憤怒當然跟覺得對方很多方面都不是很好的伴侶也有關比方有反社會人格的傾向(人生至今只遇過這一個覺得符合的人，可想見其程度)所以常常讓人覺得相處起來很不舒服個性冷漠覺得不被重視(對方說是他過去最常導致爭執分手的原因)還有晚上(咳咳)的能力所以沒有過what if的念頭唯一覺得只有如果能早點意識到自己真正的情緒或許就能避免這麼難堪不開心的飯局/場面。夢見好不容易相信他 終於正式在一起週五上課我們選了座位一起坐下課休息他離座跟女生朋友聊天開玩笑伸手拉了對方帽子一下回到座位來順手替坐後面午睡的女生朋友體貼的改上毯子然後若無其事的對我說明天下午兩點我在家辦聚會，她們也會來今天留宿看是要早點起來吃brunch還是妳要提早回家然後看我臉色不對才說妳要參加也可以啦然後很生氣的醒來。今天的夢讓我明白這個人過去了但傷沒有 只是不再與他有關。--',\n",
       "  0],\n",
       " ['短短一個小時內摧吐三次，最後一次吐的已經含有血絲，被嚇到，不敢再摧吐。自從輕斷食結束後，為了要等待身體狀態穩定，依然很嚴格飲食控制，吃東西總是秤重看熱量，外食一定找有標示熱量和營養素的，然後控制在一定範圍內。因為之前輕斷食時就被告知，如果輕斷食一結束就大吃一定會反撲復胖，因此這兩週我依然很努力控制著，只是有了四次的「半作弊餐」，因為我還是事先計算好要吃什麼，其他兩餐吃得極少讓自己有盈餘吃熱量約一千大卡的一餐，可是無論怎麼吃就是無法滿足，甚至一度厭惡食物不想吃，只好逼自己喝乳清讓攝取的熱量不至於太少，有時也會試圖想要尋找會讓自己滿足的那個食物，只是一直找不到。昨天中午後就完全爆發了，午餐為了幫朋友慶生，早餐吃的不多，點餐時選了一個熱量最低的清炒義大利麵，非常單調，而且份量少，結束和朋友的約會後去了咖啡店吃了蛋糕和咖啡，沒多久就吐了，覺得一天的熱量快到上限，覺得很有罪惡感，情緒越來越差忍不住就吐了。前後總共吐了三次，最後一次可以感覺到自己有意想把多吃的食物吐出來，教練就說要考慮是不是有暴食症的可能QQ後來教練要我飲食控制先暫停一週，進食時不再計算熱量，也不要紀錄體重變化，可是兩點多醒來時覺得有點小餓想吃點東西，吃了一根營養棒和乳清，就嚴重覺得有罪惡感，一直試圖摧吐，吐掉那些不該吃的熱量，然後就發現已經有血絲出現。輕斷食結束後體重並沒有往下減，坦白說雖然知道是正常的但我卻很焦慮，覺得自己那麼努力撐過八天的五百大卡人生，體重雖然減了4kg，可是結束後就一直卡在那裡，縱使教練一直跟我說這是很正常的現象，但我還是焦慮不滿，一心希望自己往下減，可以穿無袖上衣、穿短褲也不會傷害路人的眼睛，然而即使我覺得穿起來似乎還好，終究還是沒有勇氣穿出門，畢竟我的體重體脂還是高於正常值不少，很怕路人嘲笑。昨天被教練反問輕斷食前卡關我都沒有如此在意體態，現在減了4kg不是該覺得開心嗎？但是卡關到最後我也是無法忍受，只好接受輕斷食的建議。現在依然想吐，覺得胃裡很多食物，全部都想吐出來再大吃麥當當QAQ快被自己搞瘋，很糟。很想哭。--',\n",
       "  0],\n",
       " ['看到家人的某個部位不好，很難過....卻還是這樣煮飯做家事買東西照顧老人，上午買了一瓶之前他買的保健食品，雖然很貴，但希望有效。--', 0],\n",
       " ['我知道過去有許多Line都擁有爭議。但我有一些大群管理經驗。本身也擁有多項病徵確診。我想明訂一些規則然後試營運。@不可騷擾女性板友，強迫她得向你袒露心事。@有紛爭，我可以幫忙排解，追求對錯無偏頗。@民主制，群主只是開群者並非最大。@不得有金錢往來。@不歡迎惡意惹事者。我相信大家都是夜貓子。（像我就是。）我們只是發作的時候需要分心分享，互相鼓勵。也許這次也會失敗。但我只是想有一群人能在夜裡說話。http://line.me/ti/g/UFmKG-CvRd--',\n",
       "  0],\n",
       " ['明天約了下午諮商，但外面雨一直一直下，而且我好累，好想逃避..好想傳訊息給心理師取消明天的諮商..但又覺得如果這樣做的自己好過分，因為心理師空出了時間給我預約，等等等等等可是我真的好想逃避..才三次，我已經開始覺得兩週一次的諮商，對我的時間壓迫好大好大好大..--再回來看，才發現我的標題打的亂七八糟，昨晚果然累了XDDDD就留著不改了吧今天起床雨不下了，所以最後我去了..開了半個多小時的車到鬧區，好不容易停好車..我告訴心理師自己原本很想逃，因為下雨，因為好累，因為昨天爸媽又在情緒勒索我回家..告訴心理師，兩個禮拜一次，給我的時間壓力好大..然後心理師說..“所以妳給自己的時間好少喔”我就淚崩了心理師的意思是，諮商其實是我給自己的時間，但是我把時間都分出去了，無論是給工作，還是原生家庭的情緒勒索讓我壓力大..最後我們的解決方案是改變排程，從週六改成週五晚上..這樣可以解決週六諮商完我不想看到原生家庭的問題，但週五時間上會比較敢..那天我就無法加班，一下班就差不多要飛奔離開，然後諮商完也比較沒有時間放自己假，在街上閒晃..大概是這樣吧..先試試看囉..',\n",
       "  0],\n",
       " ['今天煮完晚餐等爸回來我叫了聲 爸爸撇頭過去沒理我我的臉好像被打了無數個巴掌得病的我該如何活下去？來自家人的冷漠真的好傷人...--剛剛試著跟主耶穌禱告了...得精神疾病非我所願...聖經說：愛能遮掩一切過錯。我願意原諒我的父親...感謝各位病友大大的回應 orz',\n",
       "  0],\n",
       " ['(雷)還記得大學住宿的時候，每當放長假/過節，室友們都會開開心心的收拾行李，拖著行李箱“回家”。有人搭客運、有人搭火車，也有人搭飛機回自己的國家，留下我一個人在宿舍，思考著哪裡才是我的歸宿。“很抱歉我存在於此”已經不記得是從何時開始，不管身在何處都為自己的存在感到罪惡。也許是以為自己是造成原生家庭痛苦的元兇，卻在高中畢業就急急忙忙自私的逃離原生家庭，在自己和家庭之間劃下界線；又也許是為了逃離原生家庭而來到了這個星球，深刻的體驗過因為品種差異而被劃下界線的感覺(#1SdpUQsa、#1SsKP7KG)。對不起，我明明是這樣的身份，卻還是不得不厚顏無恥的成為這片土地的負擔；就算世上沒有能夠容納我的地方，也不得不繼續活著。=============================================當其他人表現出想家、思鄉、愛國等歸屬情感時，我感受到的是「無家可歸」的孤獨。很慶幸地，重鬱症初發時的自殺意念給我提供了結束這段漂泊的希望：既然我們在出生前是沒有實體的，或許那個「無」的境界才是所有人最終的歸宿。死亡大概就像室友們回鄉和家人團聚那樣，或許我能透過死亡回到真正的家鄉。“你如何確認死後的世界真如你所想的那樣？”那時的心理師這麼問我。“那些難道不是你的一廂情願的想像而已嗎”“其實你並不是真的想死，而是想要一個家”理智上，我知道心理師提出的質疑才是合理的，“沒資格存在卻不得不存在”才是我的真相；情緒上，這個真相所產生的內心衝突超出我能負荷的程度，才寧願相信在那遙遠的彼岸有我的容身之處。我真正渴望的，是能夠讓我安心的休生養息的避風港，即使不用燃燒殆盡來證明自己的價值也能毫無罪惡感的待著；不用耗費大量能量懷疑是否給別人帶來不便/負面影響，而卑微的把自己縮的很小；也不用過度在意別人的評價，整天提心弔膽會因為身份、價值觀、思考方式等差異，而喪失繼續待在這片土地上的資格。(篇幅太長，續...)--',\n",
       "  0],\n",
       " ['因為不會照顧自己就一直學習著怎麼照顧自己很容易受外界的影響而忘了自己又因為忘了(還是懶呢)照顧自己非常非常在意外界的眼光~所以待在家裡的時光是可以很舒服的這就會糜爛的開始!!!我永遠記得自己大學正妹室友跟我說頭髮沒弄好怎麼出門!!!!昨天跟朋友約出門吃飯 喝咖啡他跟我你瀏海太長了距離上次剪頭髮4/16 原來已經過一個月了日子不知不覺的過去了頭髮也長長了我都沒有覺得我瀏海過長因為我就是不照顧自己的外表我會很羞愧耶 如果打扮的話是一種對父親的背叛好怪喔為什麼有這種對自己打扮有害羞感呢?不化妝 不弄好頭髮 也放任衣服亂穿昨天又在看CPTSD那本書 真的看得超慢超慢我還沒看完 因為我卡關了阿甚麼是羞恥? 我不懂這個國字的意思耶天啊我閱讀障礙又出現了我很急的想讀完 跳躍式的閱讀 越看越焦慮越看越不懂估狗了一下羞恥意思羞恥(英文SHAME)是一種因隱私遭侵害，或經歷不榮譽、不成功及不得體等事件而察覺到自己無法符合社會預期或規範，所產生的尷尬或暴露情緒。 驕傲經常被視作羞恥的相反。 當意識到羞恥時，人體經常伴隨著由自律神經系統引起的臉紅及心悸，有時更伴隨著如眼神不定等肢體語言。 其感情強度可從轉瞬即逝至深度焦慮。所以是我感到羞恥嗎?好像是吧為什麼呢?會跟父親有關係?好討厭這樣的感覺喔--人的一生其實大部分都是灰色的 如果要太黑白分明那是會活得很辛苦--',\n",
       "  0],\n",
       " ['昨天又開會，又再被要求去考證== 回家中途一陣無力感襲來，覺得快當場暈倒暴食的背後是“累”，知道之後寧可9：00上床睡覺。雖然1：00會醒來。劇荒的我我無意看了韓劇靈魂維修工，看到一個名詞叫做“陣發性暴怒” ，我的暴食應該也有這樣的原因吧！結論：只有戲劇裡才有願意陪伴妄想症患者去巡邏的醫生吧！現實中只有自己。--一定要斷手斷腳才能進急診室嗎？看吧！看吧！憤怒？哈我想直接變瘋子住院就不用工作了',\n",
       "  0],\n",
       " ['昨晚吃完飯，想說去買個新枕頭，騎到一半，冷不防，後面撞上來，我往前倒，上嘴唇著地， 然後躺在的上，盡量不要亂動，因為傷勢不明。等救護車到了，人員查看一下，幸好上唇沒毀，門牙也沒撞到，坐救護車去醫院，主要皮肉傷。然後撞我的也被送去，酒還沒醒，還在瘋，警察只有抽血驗酒精。昨晚自然沒辦法睡了，結果不是上唇嚴重, 是手腳被磨破皮的傷口痛，早上起來頭昏眼花，又躺著，到了中午起來，接了肇事者的電話，連連對不起，我也沒跟他計較。一切都是因果。--豈能盡如人意，但求不愧我心--',\n",
       "  0],\n",
       " ['增加了新的藥物——美舒鬱。副作用很多，也很明顯。像是頭昏、視覺模糊等等，嚴重影響生活與工作。藥效反而不彰，依然每天只能睡上三、四小時。白日的困倦，夜裡的思緒混亂，這是我生病以後每日面對的日常。很累。很多時候真的會累到想放棄人生。可是等我慘淡收場的人太多了，我還是不想讓他們稱心如意。在還能活著的時候就活著吧，總有一天會等到永恆的休息，不急於一時。很多事情都意興闌珊，但還是要堅持工作，如果連這最後一道防線都失守，我真的就是廢人了。--謝謝你 好溫暖我也是睡前吃，可是單眼失焦的症狀還是很明顯，看了眼科也檢查不出原因，只能猜是副作用了。不要害怕，我們一起撐下去，真的不行，就重新打造。',\n",
       "  0],\n",
       " ['真的很雜亂 我應該是想到什麼就寫什麼 想要找人講講話 不好意思-今年年初的時候交了一個男朋友 過的很開心但後來五月底時因為時間上和想法差異太多所以分開 剛好和一個摯友自殺的消息重疊到那個時候真的好崩潰',\n",
       "  0],\n",
       " ['本來就偶爾有焦慮的狀態心頭（喉頭）很緊有點不安此外沒有其他徵狀之前是一個月偶爾一周會焦慮最近連續一個月沒停過一直都是吃利福全0.5mg當緊急藥不過傍晚6點吃了可能要到9點10點才比較放鬆這次回診醫生聽了就把緊急藥改成贊安諾0.25mg說效果比較快我現在急性先試試看但我看完醫生6點吃了一顆到現在喉頭一樣緊還是小不安剛剛又吞了一顆是贊安諾對我沒效嗎？有效的感覺應該是怎樣？--可我6點吃到現在了...換之前的利福全這時候已比較輕鬆@@',\n",
       "  0],\n",
       " ['上月底突然重度發作，整天臥床，到最近才稍微好轉。雖然知道這個工作真的壓力大到讓我生病，但始終猶豫不決。開人力銀行網站，心情越看越糟。尤其是自己已經37。自己受訓兩年的技能，職缺比較少。有想投很久以前待過的一間。但不知道有沒有機會。還是想說轉行，或是換個方向。履歷不是很好看。想說問題到底在那裡？是自己太勉強自己做這行？其實適合別的工作？也不知道還要休養多久。-----Sent from JPTT on my Samsung SM-A7050.--',\n",
       "  0],\n",
       " ['不該量體重的，看到又增加的數字開始覺得噁心想吐，但其實仔細回想，我已經連續三天完全忽視熱量而且進食高熱量食物了><會胖也是正常的...昨天發現穿衣服變緊了，開始隱約覺得焦慮，可是回診後情緒難以平靜也無暇想到這件事，直到早上又想起忍不住偷量了體重，整個覺得很糟。教練老早就要我別量體重，飲食直覺控制就好，他說我看到數字一定又會很焦慮，然後就會吃不下又吐，反而對身體不好，造成惡性循環。早餐吃不到一半就想吐了...非常糟。--',\n",
       "  0],\n",
       " ['最近轉到一個節目 管教惡貓看到時已經是節目尾端了因為主人會忍不住餵貓吃各種東西，貓有糖尿病主人拍攝給傑克森的影片是她笑笑地躲進浴室吃東西怕被貓看到 無法拒絕給食影片過程都笑笑的 好像不夠正經(到真的去面對這個問題)那種迴避似的 習慣性地玩笑結果傑克森教導完再回來拜訪時貓還胖了主人像小孩一樣辯駁：我沒有給牠吃別的東西，牠就是胖了，而且牠血糖也降了啊傑克森沒有分享她(覺得)的成功認為她無法拒絕，沒盡到一個主人的責任(我覺得是成人...)這樣對待貓也無法彌補她小時候的寂寞那集標題叫做 滿懷罪惡我也是養的罪惡感很重、焦慮經常是自己需求的投射像是看到別人的貓在大空間跑來跑去像是怕牠覺得孤單整體覺得沒有能力給牠更好的生活結果到頭來好像是我其實羨慕別人的日子 想要更有品質的生活卻覺得自己不值得而沒有感覺到自己想要投射在貓身上?又像是每次出門很久回家看到寵物店 就會莫名其妙地進去買一個罐頭或什麼東西明明沒怎麼需要 就算是正餐也是網拍買便宜好多好險貓很實際 只玩自己喜歡的東西(例如垃圾)買了東西給牠也不一定理變成我買的東西才是垃圾(?那種買給牠的想像幻滅是買給我的情緒久了有比較清醒一點可是那種莫名其妙的罪惡感 讓人很不舒服就像明明是快樂的事情難以解釋的感覺到的卻是悲傷或失去比較多所以快樂的事情才這麼少對吧…--',\n",
       "  0],\n",
       " ['各位早安鄙人長期有失眠及注意力不足的問題，也因而導致情緒容易緊張、低落，目前持續在吃治療的藥物。但不知道是不是藥效太強的緣故，即使我晚上睡得再飽，隔天快到中午時就會累到一定要趴著休息一陣子才行。前陣子因為吃太好ㄌ，變胖很多......我的外觀雖然看起來偏瘦，但因為愛亂吃東西、不愛運動，其實就是個裝滿脂肪的瘦子。痛定思痛減肥，做法如下：1. 完全戒糖，飲料只喝無糖豆漿跟無糖茶2. 不吃精緻澱粉3. 168斷食（超困難的QQ）4. 點心只吃水果5. 每天做簡單重訓30分鐘以上只是進行了一個禮拜，明顯感覺到身體上的改變，精神變得好很多、專注力也提升了一些（後來去查發現的確有糖會影響ADHD的研究），進而心情也變得好許多，體態雖然沒變多少XD但這個間接效益也是值得了。不過我離不開甜點QQ所以給自己星期五當甜食日XD，開放自己吃點心跟垃圾食物，就是今天！各位不妨試試看，一項一項開始進行就好~千萬不要給自己太高的門檻，慢慢來9好。另外最近迷上刺繡><閒暇時間都在刺，遠離網路的感覺也是挺不錯的~-----Sent from JPTT on my iPhone--',\n",
       "  0],\n",
       " ['被確診憂鬱症大約三個月中間換了不少次的藥物作為調整。就近三週的固定藥物是景安寧、欣得眠、得原緒、比博寧但我發現我最近瘋狂長痘痘！幾乎都是在下巴附近，真的是崩潰不已。護膚品長期以來一直是穩定使用輕鬆美膚的全套產品，照理來說不可能會是它導致。想問問板上的同伴們有因為服藥長痘嗎？今天早上回診時有問過醫生了，但醫生的回覆是沒遇過特別提到會長痘的反饋。讓我有點沮喪。另外因比博寧對我而言效果非常不佳，注意力沒比較集中之外，菸還不自覺的抽更兇，因此醫生替我換了易思坦。希望新藥不要再讓我長痘，難道我真的要一直換藥測試嗎QQ謝謝大家--還好目前我沒有變胖的問題QQ目前使用外用A酸，如果還是持續長痘就會去皮膚科掛號看看是否合適吃口服A酸了QQ還好我的藥單副作用都沒寫到會變胖QQ經你的提醒讓我想到我的這些藥的副作用剛好有口乾跟便秘，所以近期滿常喝優酪乳的！！或許有可能跟這個有關，接下來改吃益生菌試試看好了QQ如果沒改善會去婦科檢查謝謝你我戴口罩的時間很短，平均一週兩天而已QQ這倒是真的，之前有為了不長痘痘戒拿鐵改喝美式，看來可能真的和優酪乳有關奶好戒，蛋超難QQ目前醫生開給我的藥物似乎不會讓我增加食慾，再加上我的工作每天會大量流汗+環境炎熱，更沒食慾但還是希望我不會變胖QQ',\n",
       "  0],\n",
       " ['請問有人自身是躁鬱症或憂鬱症患者，又是他人憂鬱症的陪伴者嗎？可以分享一下如何調適自己以及陪伴對方嗎？--', 0],\n",
       " ['大家在去看醫生、拿藥的時候有沒有遇過很不舒服、很討厭的事？我先來，我從大醫院轉診診所；大醫院拿藥都會抽號碼牌，診所沒有，要去藥局，藥局也只提供身心診所拿藥，所以來拿藥的都是隔壁的診所看診的人，我不知道他們是有什麼症狀，可是一直一直一直被插隊（特別是插隊還靠很近！不論男女都是）真的讓我超級不高興......但我又說不出來。雖然藥局似乎是按照診所看病的先後順序給藥，但那感覺......越來越不想去看醫生了............。--',\n",
       "  0],\n",
       " ['【大紀元2018年01月09日訊】「胡風反革命集團」案是五十年代的「文字獄」之一，是中共制度化暴力的產物，雖然針對文藝界，但和1951年對《武訓傳》的批判，知識份子思想改造運動，1953年對俞平伯《紅',\n",
       "  0],\n",
       " ['忙碌的一整天，找房真是件煩人的事，騎了一個小時的車，到現場才剛我說已經租出去了，到底是有多搶手，上午才po出來的物件欸......既然都去了就順便把租屋網上其他的備選通通都打過一次，至少還看了一間，要回家的時候天色變的很怪，是我極度討厭的昏黃。偶爾黃昏時的某個陽光角度會有這樣的光線，是一種介於白天與黃昏之間的，壓抑的日光感，不是夕陽西下的那種黃昏，而是昏黃，但確實也通常出現太陽要下山的時候。其實不知道為什麼這麼討厭這種昏黃，每次總是會覺得恍神，所以我通常盡量會避開黃昏待在外面，沒想到這次才4點就出現了！！！瞬間焦慮指數上升，硬著頭皮騎完，到家才想起，對了原來今天是日蝕的日子，大家都在各種分享日蝕照片跟影片。不過至少安全到家，而且知道了以後也要避開日蝕的時候外出......--',\n",
       "  0],\n",
       " ['妳過的好嗎？分手之後的我們曾像這般簡單地噓寒問暖，但那種沒有意義的對話，實質地讓我感到難受。我不敢過度干涉妳的人生。因為，我認為自己沒有真心實意的關心妳。我的身上似乎背負著不可言喻的枷鎖，難以忍受的沉',\n",
       "  0],\n",
       " ['剛是第一次吃離憂醫生交代要在睡前吃但我半夜卻因為強烈自殺感而醒來了請問有人也是這樣的嗎？這是藥的副作用嗎？--那就奇怪了，我很好睡的。很少半夜醒來剛去查其它人的經驗，發現剛服藥會有強烈自殺感好像是副作用之一，要持續三個禮拜才會減輕。1;37m推 zlhienn: 我之前吃離憂狂做惡夢... 07/16 12:07',\n",
       "  0],\n",
       " ['最近在戒藥，身體不甚舒服，但為了不要第二次TMS做了又是徒勞，還是很努力、刻苦的一天只吃一顆半的藥。連阿達醫生準我吃，但確實會影響療程的悠若丁都不吃了，晚上睡睡醒醒，一直做夢，注意了時間更痛苦，因為發現時間過的好慢，怎麼做了三個夢才過20分鐘，後來慢慢調適、習慣，才不去注意時間這幾天都開冷氣睡個覺，最近看東西總是有點模糊，眼睛酸酸的，有點畏光，就索性不上網發文，結果回頭看這個地方還是很悲傷你們給我看你們曬傷的地方不是要我給你們強光是給我權力看看你的傷我會像月亮一樣晚上給你細細的微光雖然不足以灌溉你的心房但至少可以照亮你的夜光————我的ig康復日誌po_ya_chan原諒我今天的文這麼短，但我眼睛好痛呀！--',\n",
       "  0],\n",
       " [\"https://youtu.be/qVdPh2cBTN0清清淺淺的音樂Well you look like yourselfBut you're somebody elseOnly it ain't on the surfaceWell you talk like yourselfNo, I hear someone else thoughNow you're making me nervous這麼溫柔的歌曲卻又像是種嘲諷，看起來是自己其實卻不是自己。一如所有多餘的情緒在生理期隨著經血流出體外，變得稍微清澈一點的自己，討厭那樣的歪斜，卻毫無辦法。想起好久好久以前的美好回憶，大家一起聽著音樂聊天一邊畫畫的回憶，在灼燒的火焰下，深綠色湖水中的自己，曾經有這樣的一個人和一雙手，屬於深青綠色與黑色的人。罐子裡的碎片今天很安靜，我稍微搖晃它也沒有反應，就像是普通的碎片一樣，不會是死了吧？還是睡著了呢？不過這樣也好。聽說人有三魂七魄，偶爾受到驚嚇或什麼會少掉一些靈魂，殘缺的靈魂還是可以活，所以即使碎片真的一直這樣也是可以活的，看起來不是自己，或真的根本就不是自己也可以活的。--\",\n",
       "  0],\n",
       " ['100歲的父親跟70歲的女兒互相勒索著100歲的父親也習慣著勒索所有的子女、媳婦、孫子女等等等等等快70的兒子在旁邊為了當孝子，勒索著自己的女兒出來解長輩們的爛帳65歲的女兒習慣被勒索，看著姐姐跟爸爸互相傷害責怪著姐姐然後關我什麼事因為我就是那個被勒索要出來收爛帳的孫女所以我已經一個月不想回家了--我爸剛剛低聲下氣的傳訊息跟我說「再去跟姑姑說一次，禮拜六幫她慶生好不好，拜託麻煩什麼鬼東西啊！！！！！！這時候就覺得還好我已經不住家裡了..大衛一樓那句話，放在這裡真是怎麼看怎麼適合..我爺爺很依賴我，凡是大事，一定指定我來做例如主辦他的百歲壽宴還有他的醫療決定權也指定給我了..（其實那只是留給醫院的聯絡資料，但他很鄭重的告訴我，他指定我來為他做決定）平常父執輩的紛爭大家拉不下面子，不肯下臺階，最後就叫我去裝傻裝乖裝可愛的逐個撒嬌，一個個請下臺階..但我真的累了..我只能逃避不回家，不能抱怨，不能說累不然就是下一個被冠上不孝罪名的撒嬌也是需要天份的呢(無誤',\n",
       "  0],\n",
       " ['超討厭人說自己沒有選擇沒有你喜歡的選擇不等於沒有選擇好嗎！！\"你喜歡\" 這三個字不是選擇是什麼？！喜歡什麼討厭什麼不是選擇？？？跟我莊肖維什麼掯有種做決定就有種承擔責任比實際上做出讓人不滿的決定更讓我憤怒的就是這種鬼話。那些決定我不喜歡但我還能理解要好處還要好看就讓人憤怒到一個想翻桌--',\n",
       "  0],\n",
       " ['剛吞了幾排藥嗯 至少不會留下傷痕 也不會死 也不會胖藥效發作前總是不知不覺吃掉一堆藥還好之前安眠藥囤了不少沒到需要洗胃的程度 版友不用幫我緊張反正他也不會在意我好想要被愛但我只能透過OD來逃避現實--抱歉讓大家擔心了謝謝你們 很溫暖 我被救贖了謝謝妳們 真的 真的感恩',\n",
       "  0],\n",
       " ['全國自殺防治學會持續推動自殺防治，觀察去年收到的自殺通報有3萬5千人，雖然人數比前年下降，不過青少年自殺人數卻是比前年增加，值得關注。衛福部統計去年有3萬5200多人被通報有意圖自殺行為，相當於每1小',\n",
       "  0],\n",
       " ['憂鬱症定義，要兩星期持續低落，食量異常變動或原本感興趣的事失去興趣，很長一串啦但，我為什不開心還要別人定義我就知道我失控了連續幾天了然後，我決定靜靜地，不想要用力地做些甚麼，而是承接自己--',\n",
       "  0],\n",
       " ['小粉紅再捧阿，超有效率不就好棒？河北邢台市強推火葬 刨棺挖墳把下葬屍體強行火化中國河北省今年開始強制推動殯葬業改革，邢台市爆出官員強力執法，把下葬不久屍體挖出，另有官員家裡未能落實政策遭到撤職，引起民',\n",
       "  0],\n",
       " ['都是沙漠罷了東邪西毒電影裡，洪七想看沙漠後面是什麼？歐陽鋒說不過也是沙漠罷了，但洪七不會聽，因為他如果沒有去看的話會不甘心。我不禁悲從中來，胸口好悶，絕望無比。--http://pilikang.pixnet.net/blog胡愛晏 做妳所熱愛的事情，然後讓別人為此付錢給妳。 \\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000\\u3000丹。米爾曼＜生命如此富有＞p.83--',\n",
       "  0],\n",
       " ['發作時除了哭不出來之外就會一直看著天花板一直盯著 一直盯著面無表情腦袋不停運轉又好像根本沒在想什麼我愛你天花板你總是能讓我看不膩只有天花板也會靜靜看著呆滯的我--',\n",
       "  0],\n",
       " ['今天無預警發作了，不知道是因為天氣，還是累積的疲勞感爆發。不想動彈，不想吃東西，不想去洗手間，也沒有去上班。正值年中考核時機，好害怕丟了工作。可是我真的好累好累。我笑了好久了，可是再怎麼笑也騙不過自己真實的心情，那種幾乎一潭死水的心情。明知道都是暫時的，但是這時候還是好想要有一個句點。--',\n",
       "  0],\n",
       " ['今天去銀行辦事，交印章的時候又不受控制的手抖。櫃：你...你怎麼手在抖！？我：可能是因為喝咖啡的關係櫃：你一直以來喝咖啡都會手抖嗎我：對啊櫃：為什麼你會這樣啊我：體質關係吧櫃：你真的沒事吧我：我很好啦自從開始吃這顆藥，類似的對話不知道重複多少遍了。其實在看精神科之前偶爾也會抖，只是沒抖得那麼厲害。因為知道自己有這個毛病，所以會自動避開精細的實驗，是選擇專長的決定性因素之一；打字的時候手腕要靠在桌上或墊上；不管技術再好，指甲油也常塗得亂七八糟；因為不想像今天一樣吸引不必要的關心，甚至會避免伸手遞東西給人家。好想減藥啊，但目前不能沒這顆藥，所以只好忍了。我寧願手抖得跟地震一樣也不要憂鬱到爬不起床。--',\n",
       "  0],\n",
       " ['爛死人的醫生還好只是代打不是長期不然我會活活氣死問診重複多遍是怎樣馬上失憶嗎？真的是糟老頭欸問藥的部分也不清楚後來還跟我說「還是下禮拜你再問陳醫生好了？」哈囉老兄你是多無能啊？有沒有一點尊嚴？我很怒！在診間小發飆「那我這禮拜怎麼辦？什麼都要等下禮拜，我這禮拜藥是要怎麼吃？？」買雨衣老闆白癡耶 拿錯顏色我爸說啊你怎麼不檢查我說就大雨啊！它包裝起來我怎麼看到顏色？？？是老闆先拿錯顏色欸幾秒的事情他竟可以馬上錯誤回家也繼續發飆想到晚上得陪笑臉跟同事吃飯就超不爽的煩死了 都說我不想去了還不給拒絕今天唯一值得慶幸的是沒遇到那個討厭的人--',\n",
       "  0],\n",
       " ['想到心理師說的許願反正不用錢多許幾個也沒關係不用因為生病或經濟煩惱在意的人都在身邊好好吃飯好好睡覺-----Sent from JPTT on my iPhone--',\n",
       "  0],\n",
       " ['轉彎前一秒打方向燈不稀奇稀奇的是自己錯了，還罵人的那種不歧視，但大多都是大媽、阿北年齡層的（年紀輕的就是無照駕駛吧）他們駕照拿到久了，以為自己很熟練吧？今晚準備過馬路，在想事情看到綠燈亮起，我就直接往斑馬線走去左邊要闖過去的一位三寶阿伯馬上大罵我「啊妳是不會看路喔！」他氣噗噗，但我也不是好惹的莫名其妙，綠燈過馬路還被罵馬上回他「我綠燈欸，你紅燈！」他差點撞上我，嚇到了所以生氣吧？（還是因為沒能闖過路口而生氣？）阿伯被我回嘴很驚訝，更生氣，還想繼續罵但我繼續走我的斑馬線拜拜了~呵呵不過守法真的不夠啦即使是綠燈，我也會左右張望才過馬路今天疏忽了，綠燈亮就走向對面好險沒被撞到不然我會氣死吧，死三寶黃燈轉換紅燈大約五秒很多人為了闖過去發生事故大多事故都是貪快我有個親戚就被貪快的司機給撞成植物人了但司機剛好貧窮，僅有的還脫產給別人了...（我親戚一生被毀了，家庭也破碎，好慘......）馬路三寶雖然很討厭，但既然他們存在還是自己小心一點比較好雖然常常夢想著「被撞死該有多好」但是被討厭的大媽或阿北撞到應該會非常不爽 還是別種死法好「老害」是歧視用語但也不是一點原因都沒有只是不能以偏概全啦除了親戚被撞成植物人自己的老爸也被鄰居給撞上從此以後下樓梯、運動都再也無法如以往一樣下樓梯甚至會痛，很慘但那個鄰居阿北卻因為我們向他要求賠償從此看不爽我家人再也不跟我們打招呼爸爸的一隻腳骨折 再也無法恢復以往他卻只用六萬元就以為很多了因為年齡就以為自己比別人厲害這種想法到底是從哪冒出的？每次看到長輩對我說教或是以自己的觀點詮釋我的人生就覺得他們愚不可及不過要說愚不可及的，我也是吧今天做門薩的網路智力測驗我才95，不知道算不算智能不足但題目很好玩啦，版友可以玩玩~朋友玩這個135是怎樣...不愧是有會員資格的怪人（哼以下網址https://test.mensa.no/--',\n",
       "  0],\n",
       " ['被蘋果鳥了一個多星期只有safe boot能開機startup app全移除 磁碟修復 硬體測試 cache刪除還是鬼打牆而且safe mode只能讀蘋果格式的外接硬碟正常開機能讀取的exFat格式讀不到本想說弄個usb啟動以後萬一有問題也可以用來救援卡半天換了三台電腦2個os版本兩隻usb網路說大約半小時最後抱著看到底能耗多久的態度顯示15分鐘 安裝整整跑了將近2個半小時而且使用者名稱設定還有bug只能暴力重開後來覺得不跑graphic介面總可以吧single user mode居然一直loop(當然verbose mode也一樣)只跑command line也不行是那門子莊孝維的道理跑去問果粉軟體工程師朋友 想說他比較熟蘋果回我說single used mode是管理其他使用者的超級傻眼比我這個文組的還不熟Unix是那招整個覺得問道於盲想想到現在問過關於蘋果的進階問題沒一個得到解答的(感覺蘋果使用者就一個傻用就是了?)後來一查看來好像是新一代蘋果有限制神煩到一個境界最後還是只能土法煉鋼terminal備份重裝os完事只是很多年沒用過unix指令都忘得差不多了再上個星期整個週末都在弄網路從星期三就斷網原服務商每次打電話都要等50幾分鐘來修要等一星期立刻決定換服務商結果還是一直有問題電話打了十幾次第二次來的裝機的人弄了兩個多小時才弄好(要不是被我質疑 覺得拼了一定要裝好 搞不好又跟第一個一樣 不行拍拍屁股就走了）買了被採購同事嫌舊產品的小紅點鍵盤今天收到迫不及待試用根本超棒<3<3<3<3<3連手機都能用小紅點 讚又穩定不像蘋果無線鍵盤吃AA電池三天兩頭就在那沒電從上次到現在已經換過第二次電池又只剩15%而且根本沒什麼在用超想丟進垃圾桶........人真的是種非常容易預測的生物朋友常事後說原來妳之前說的是這個意思/又被妳說中了很無趣才剛說過關鍵在tunnel vision導致忽視邏輯(攤手邏輯謬誤的話 推導無論大還小都不可能正確基本功有問題 當然能涵蓋的範圍很小就像基本英文不行別人不可能跟你談語言學一樣(再攤手可是總有些人覺得基本不行給他進階就能飛天(到底?人貴自知之所以貴在於唯有認知自己在哪裡才可能知道什麼需要改變改善才有可能往前走不過那很需要面對自我感覺不良好的能力跟意願就是另ptt是公開版面公開文章任何人都有權力推文版規規定可以自刪推文不等於推文違反版規....昨晚重看了一次拉拉鏈有些東西改變了我開始學習切割期待你存在的人生。--',\n",
       "  0],\n",
       " ['唔，其實是之前DC Fandom的資訊????由蒙特利爾工作室開發的遊戲，劇情由蝙蝠俠布魯斯·韋恩死亡為開端，目前看來與貓頭鷹法庭有關系。出現的可操控角色為蝙蝠系家族成員夜翼、紅頭罩、紅羅賓、一代蝙蝠',\n",
       "  0],\n",
       " ['女友從前年底發病到現在已經與憂鬱症相處超過一年半了，初期很容易就急性發作(焦慮、憂鬱導致非理性行為)，後來找到比較適合的藥之後有比較趨於穩定。去年有陣子她自己覺得狀況比較好之後就自行停藥了，後來斷斷續續有再吃一些藥、換藥、又再換回原藥、又再度不吃藥。推估她主要不喜歡吃藥的原因有：沒有想好起來、本來就討厭吃藥、不確定自己的狀況是否因為憂鬱症導致、覺得自己可能好了、藥的副作用(她是吃妥富腦，原本穩定吃的時候都沒有副作用的問題，但不知道是否因為自行停藥一陣子，又突然吃且一次吃到偏高的劑量所導致)關於沒有想好起來的問題我覺得可能是最重要的，因為她覺得不知道人為什麼要活著，以及覺得生病的時候大家都會對她比較好(在這邊道歉我確實因為她生病非常寵她，所有她不想做的事都會幫她)，而且她也不對未來有期望(曾跟她討論過如果憂鬱症好了可以有更多體力出去玩、可以喜歡做更多事，但她都表示沒有期望)一直以來我都會嘗試用各種方法來支持她、陪伴她，只要是查到資料可能比較好的方式我都願意嘗試，例如同理、陪伴、傾聽、盡量不給出有壓力的鼓勵、陪伴她運動、鼓勵她多找朋友、鼓勵她諮商...等我想得到、找得到的具體方法我都試過，然而我也不確定是環境因素還是不穩定吃藥的關係，她的狀況一直都在低處起伏，但我想既然我可能沒有辦法幫她改變太多環境因素，那是否有辦法鼓勵她重新穩定吃藥呢？至少可能是個契機感謝大家看到這邊，想知道大家都是怎麼樣願意穩定吃藥的呢？陪伴者又該怎麼鼓勵會有辦法讓她比較願意吃藥？最後抒發一點自己的心情，其實一路走來也常常會覺得自己的努力好像都被否定，到最後絞盡腦汁也想不出還能夠再做什麼，好像什麼都無事於補一樣，有點習得無助的感覺，但我還是希望有一天狀況可以慢慢好轉，所以想來尋求大家的意見，不論是自身經驗、建議或是覺得我做不好的都希望大家能跟我說~--感謝你回我一篇文，但現在好像已經看不到了，我有寄信給你，方便的話再請你回我喔~(雷)她目前還願意活著的動機好像是不想在自殺後被別人、被社會覺得不負責、沒有替身旁的人想，所以常常想在路上剛好被撞死就好了(但她在路上還是不會主動做出危險行為)不知道這樣子的動機要怎麼樣強化？感覺強化消極的動機好像也有點不太對，而且其實我覺得那樣子的想法是源自於社會對憂鬱症患者的偏見與歧視05/18 02:26醫師跟諮商師都知道她常常不服藥，半年前跟她一起進去診間看過醫生，醫師說他能理解病人要長期吃那麼多藥是很痛苦的，自己感冒藥就可能忘記吃了，何況是要每天吃那麼久的藥，所以鼓勵她穩定吃藥但是病人不吃醫生也不會責備與強迫。諮商師似乎也只問了她目前不想吃藥的原因，沒有特別提出什麼想法(沒有想好起來是這邊女友跟諮商師說的，回家後我問到跟諮商師聊了什麼她跟我轉述)我了解憂鬱症可能是非常長期的歷程，如果真的沒有什麼能做的話我還是會繼續陪伴她。想知道是在什麼樣的情況下會需要去住院呢？她曾說過自己想去住院，因為或許就可以獲得大家關心。但我們都不了解住院環境，擔心如果裡面環境她不適應會不會讓病情惡化',\n",
       "  0],\n",
       " [': 覺得你文章有趣: 有幾個點想跟你分享，因為我跟你某些想法有雷同之處: 1: 報應到底是真是假: 其實嚴格來說，我不相信報應，跟神佛: 但我信有鬼: 報應其實是由很久前的一群聰明人，想出來的一套說法: 因為人類社會需要一個秩序: 訂下很多規則，這樣子人類社會才能正常運作: 不會有大動亂 其實我有想過所謂的宗教是什麼耶！因為看了很多影片的關係，我覺得宗 教有可能是各地區的神，透過人在世的時候，所設定的一種規則，因為人 其實是外星人的後代（看老高的影片所知道的，但是不是唬爛我就不知道 了。），然後人的肉體無法離開地球，所以其實地球是我們的牢籠，只有 死後才能化成靈魂去別的世界，然而如果犯了什麼錯或做出什麼壞事，就 有可能再次受到懲罰，或者去到別的世界，當然這只是假設。 像白曉燕命案 https://youtu.be/BqjtrGZZGS8?t=997 故事裡說，幫凶張志輝被帶到命案現場，有一個有陰陽眼的調查員，說看 到白曉燕帶著五個青面獠牙的人到現場，然後張志輝才一直不斷的磕頭道 歉認錯，這代表死後還是有所謂的法律與秩序的，不然白曉燕的冤屈要怎 麼伸冤呢？ 還有就是白曉燕頭七的時候，有很重的臭水溝味，我覺得那代表她有回家 ，但不知道之後還能不能回來？我是覺得她可能要去別的地方了，所以才 會回家見她媽媽白冰冰一面，我覺得這是宗教可信的一部分，說人死後七 天會回家，所以我想人死後還是有規矩和秩序的。 小林村風災事件 https://youtu.be/IrIZCAAaxlk?t=54 這個影片可以給沒看過鬼的人看一下，我自己是以前有見過，所以覺得還 好。 總之我會覺得我自己看自己的人生，以前常會覺得跟什麼上輩子有關，不 管到底是對是錯？我覺得都不應該再用宗教去看人生，因為那會變得很偏 頗，沒辦法很中立的去看待事情，所以才會覺得事情還是應該要多點角度 去觀察，老是在煩惱上輩子的事，連這輩子都還沒處理好，再去煩惱上輩 子，那真的是給自己找麻煩。 反正人總有天會走，或許到那一天自己就會明瞭了。--我們都會期望現實世界中，有個人可以拯救我們，幫助我們面對困難與解決問題，但現實生活中並沒有人會來拯救我們。我們能夠做的，就只有每天不斷的犯錯與尋找答案。-- 我記得老高有講過，人類其實是外星人與不知道什麼物種結合的後 代，而且外星人的壽命有到上萬年，然後就一代不如一代，他影片 中的舉例好像是蘇美文化的王還是什麼的，我記不太住。 至於為何會說地球是人類的牢籠？不知道你有沒有發現，人類除了 地表以外，是無法生存在高空與深海的，高空有鳥，深海有魚，而 人只能活在表層，所以感覺起來很像是被困住那樣。 而且假如你有看過王崇禮老師的影片，每次媽祖幫忙處理事情，都 會說讓冤魂有個後路，也就是讓冤魂有個去處，不知道那是不是就 代表是別的世界？ 所以人的生命不是一個終點，這世界也可能有別的地方而沒被發現 ？只能等到死掉的那天才知道事情的真相。',\n",
       "  0],\n",
       " ['煩死了 我 我好煩啊啊啊啊啊啊到底要這樣子搞多久 煩死了煩死了煩死了煩死了不要再吃完安眠藥之後騷擾別人了 我到底 能不能別這樣好不容易交了新朋友要維持以往的正常形象能不能正常點 犯賤的自己 垃圾的自己 沒用的自己無法自律的自己 噁心的自己 讓人作嘔的自己 討厭的自己無聊噁心討厭厭煩犯賤作賤噁心噁心噁心噁心噁心噁心--',\n",
       "  0],\n",
       " ['很多人都在對憂鬱症患者說自殺不能解決問題那活著問題就能解決嗎？也有人說自殺需要很大的勇氣但其實對他們來說活著需要的勇氣更大當然離開不是唯一方式但卻是一種解脫是逃避嗎？我覺得不是只是用了另一種方式面對那',\n",
       "  0],\n",
       " ['不是陰天就姑且算是晴天但好像不是廣義晴天之前的我更喜歡happy ending彎彎繞繞千百曲折尋來的甜美果實滋味最好曾經覺得日子已經如此苛刻了才應該多看點愉快的故事，調劑身心大哭一場後還可以真心實意的為結局露出一個笑容不是說討厭悲劇，只是更喜歡HE，一個輕鬆非真實的結尾，令人嚮往接著我開始整日以淚洗面不哭了也沒有好念頭，全都是一些說出來會被他人側目指指點點的東西只能藏著掖著關在黑房間，一邊希望它永遠別再跑出來，一邊又偷偷靠著它得到救贖，然後更加嫌惡自己這時候，我對悲劇的熱愛衝上了一種瘋狂的境界挖心的剜肉的，孤獨的愛情最好、破滅的夢想最真、得不到的永遠最美HE的作品都好像少了什麼，像五分嫩肩牛排少了鹽巴好像不靠點外力刺激我會不知道我活著掛在臉上的愉快如此飄渺，風吹一下就消失了刺在掌心的疼痛卻是最為真實，一直提醒著：我還在疼，還在感受這個世界至此，渴望悲劇，無以復加--',\n",
       "  0],\n",
       " ['因為持續四點多五點才能入眠的情形(而且我租屋處房間窗戶是太陽升起的方向，又是頂加，沒有其他人幫我當陽光，夏天的陽光六七點就會逼醒我，裝了窗簾怕房間陰暗心情不佳，不裝又亮又沒有隱私對面頂樓曬棉被都可以看光光我，所以裝了一個沒有用的亮色系窗簾，依舊可以跟著陽光起床)今天醫生依然做雙側的治療~左側是65的高脈衝，右側是80的低頻傳統，讓我放鬆，這次醫生讓我在打低頻TMS時專心在呼吸上，不加入談話(雖然腦子還是在亂轉各種想法，還想到昨天晚餐自己泡的紫蘇梅飲？！)睡眠不足讓我整個人像樹懶一樣慵懶，但是耐心不足易怒的樹懶，對身邊的一切感到不耐。結束之後，疲憊異常，但因為尚有行程沒有馬上回家，還累到頭痛很想生氣，但當晚還算很好睡，隔天早上約十一點起床。抱歉又大拖稿，感覺睡眠問題因為自身習慣問題似乎還是沒有解決(週五一點多睡但週六又睡不著一路到早上八點……) 似乎還是要避免睡前情緒起伏、不要看手機、養成睡前儀式(例如刷牙、廁所、看書、聽輕音樂冥想或瑜珈等)明天要回診&迎來第十次的治療，有在思考是否要跟醫生商量先緩緩不要一次做完二十次而是先觀察成效而定。明天待續=)感謝閱讀的大家=) 希望明天也是大家的晴天=)--',\n",
       "  0],\n",
       " ['沒有理想的人不傷心/新褲子樂隊https://reurl.cc/QdK6RO我最愛去的唱片店昨天是她的最後一天曾經讓我陶醉的碎片全都散落在街邊我最愛去的書店她也沒撐過這個夏天回憶文字流淌著懷念可是已沒什麼好懷念可是你曾經的那些夢都已變得模糊看不見那些為了理想的戰鬥也不過是為了錢可是我最恨的那個人他始終沒死在我面前還沒年輕就變得蒼老這一生無解沒有我的空間沒有我的空間沒有我的空間你曾熱愛的那個人這一生也不會再見面你等在這文化的廢墟上已沒人覺得你狂野那些令人敬仰的神殿只在無知的人心中靈驗我住在屬於我的豬圈這一夜無眠我不要在孤獨失敗中死去我不要一直活在地下裡物質的騙局匆匆的螞蟻沒有文化的人不傷心我不要在孤獨失敗中死去我不要一直活在地下裡物質的騙局匆匆的螞蟻沒有文化的人不傷心他不會傷心他不會傷心他也會傷心他也會傷心傷心--',\n",
       "  0],\n",
       " ['但其實只是因為蠟燭兩頭燒而且即將欠下超過5萬元的債因為種種事情導致一些好心人(雖然我看不慣他們學長欺壓學弟妹的作風)一直安慰我、請我喝東西或約我出門或比較常跟我聚餐但其實我內心都還沒真正當成朋友因為他們並非把每一個人類當成平等簡單來講，這兩個人和我道不同不相為謀而我真正擔心的，是那個五萬元的事--',\n",
       "  0],\n",
       " ['我的婆婆殺了我嫁來的幾年，每天過的膽戰心驚，我還是太天真，以為自己能變正常...天天看人臉色活著真的很累，不是想死，是活不了了三不五時的言語霸凌說錯一次話，就無視你、恐嚇你。夠了我連想正常點活著都不行',\n",
       "  0],\n",
       " ['最近愈來愈胖了又像之前用藥一樣所以試著自己把藥減掉心裡很著急不喜歡這樣的自己從去年做完RTMS之後好了很多也規律的就診半年了什麼時候可以完全的好呢好想輕輕鬆鬆的做想做的事情好想沒有壓力的做自己想做的事情如果買東西是我憂鬱的解藥那我能不能去做呢最近常常都這樣在腦內播放著夢想讓自己心裡能夠好受一點--',\n",
       "  0],\n",
       " ['騙家人公事沒回家吃飯，我已經騎到診所門口了，但看到門口的牌子寫了三個大字：XX科，又立了另一個牌子說跟警察局連線，我看了好害怕（抱歉無意冒犯，我看評價蠻好的，只是我比較敏感）。而且不知道為什麼門沒關，我看得到裡面的人，他已經掛號坐在那邊玩手機，我找別處停車，但都是水，我腳全濕掉，我逃走了。我現在坐在騎樓發文，看到工作訊息也是馬上回，忽然覺得公司很好，我是不是有毛病？ 然後家人也同時訊息問我吃飯了沒？我反思，我一週內又想去看第二間診所，是想獲得什麼協助？只是職業倦怠想換工作但很焦慮，我這種蠢問題去問醫生幹嘛？ 有跟幾個朋友談，有的說叫我去投看看，也有說這樣會不大好找工作。我什麼都沒去做，就一直擔心，根本就是莫名的擔心，而且在擔心的同時，居然會覺得原本的地方算不錯了？！就一直自己打臉自己。就算再撐到明年過年後（應該無法了），還是要離開，不如早點走，不然年紀又多一歲。我還覺得自己很多地方都十分需要改善。--',\n",
       "  0],\n",
       " ['總是不知道甚麼時候來臨就又來了開始這麼一兩天我知道應該去洗澡會好一點我知道應該去運動走一走會好一點可是我想先打開電腦 上來看一看各位版友的文章心情反而覺得心情有點舒緩那些文章講出了我的心聲我的痛苦我的難過感到共鳴著在板友文章推文我寫的建議安慰都像是在同時安慰自己並不是我給予的是被反而安慰反饋著好像有那麼好一點 在我關心別人的同時我也關心到我自己在我認真閱讀每位板友的一字一句我也在認真閱讀我自己內在的聲音我感同身受 我的難過得以釋放我的憂鬱得到同理 我的那些不知所以然的情緒都可以釋出就在我一直睡不想醒來的同時 想著澡沒洗 早餐也沒食慾吃還有貓要吃飯了 狗該洗澡了 我也要動一動起來要刷牙洗臉上廁所 起來要 吃藥吃營養品 起來要擦藥要擦保養品起來要整理儀容 因為不想面對醒來的一堆事情 我一直睡一直睡到我尿急我要上廁所 門外的貓在靠夭一直叫著我我想我寫著文字的同時也釋放了一點甚麼心情終究會好多 等著吃飯 等著吃完飯吃藥等著洗完澡的自己我就在想到底是甚麼引起了黑暗看的電視劇?靈異街11號嗎?還是我爸跟我講話?還是我沒出門下雨天?還是朋友很多天沒回我的訊息?想著想著就更憂鬱了現在牙也刷臉也洗 貓也餵 吃好藥 吃了營養品 擦好保養品甚至棉被也折了 文章也寫了這樣就好了 是嗎 應該是吧--人的一生其實大部分都是灰色的 如果要太黑白分明那是會活得很辛苦--',\n",
       "  0],\n",
       " [': 深夜了: 失眠了: 覺得自己活著像累贅: 打個1995都說忙線: 上天真的很愛開我玩笑: 甚麼都可以不順……剛好看到這篇，就去查了一下資料。2019年全國1995生命線個案數報告：總來電數58萬總接聽數19萬總有效處理數17萬換算下來，平均每一分鐘就有一個人打過去；約三成來電會被接起；平均三分鐘處理完一件。不同時段、縣市來電人數不一，如果剛好在尖峰時段(例如晚上)打過去更不容易被接聽。另外，去年志工人數2548，一人平均處理67件來電；40-60歲族群佔約一半；以精神心理問題諮詢居多，其次是人際關係(e.g.家庭、感情)；總共約9%個案有自殺意念。資料來源：https://reurl.cc/9EAOen--',\n",
       "  0],\n",
       " ['請問有在諮商的各位最近接到以前去過的心理診所她建議我去做深度心裡治療我跟她描述說我現在也有在諮商，大概是怎樣怎樣她就說：那比較接近行為認知方面跟深度心裡會有點不同大家有類似的經驗可以分享嗎？謝謝大家--',\n",
       "  0],\n",
       " ['你還是一如以往我知道不是你無感只是為了我堅強可是我卻只感覺勉強。勉強自己回應勉強自己笑--', 0],\n",
       " ['男友有重鬱症當他遇到外來刺激很容易情緒爆發甚至想砍人殺人已經有陪他去看精神科也有安排心理諮商但在他的生活裡最親近的人是我我承擔了許多他的負面能量關於身為他的伴侶有什麼我能做的已有在版上爬文要做到真的不容易尤其是當他發作的時候我會很焦慮不安要讓自己不要過度擔憂對我也是挑戰所以我希望來版上找看看有沒有陪伴者可以加入的賴群可以相互提醒陪伴就好 不要那麼想幫助對方當伴侶發作時如何拉回自己的狀態 穩定自己可以相互交流 或是互相吐苦水也可以增加我對憂鬱症 重鬱症的理解謝謝大家--',\n",
       "  0],\n",
       " [\"三四月份的時候才感覺自己好一些但最近又像被淹沒一樣無力掙扎只能窒息因為之前吃史蒂諾斯容易想不起事情所以改吃宜眠安（順便幫助改善多夢）但最近想忘記事情所以又吃回史蒂諾斯結果不但睡不著也忘不掉（討厭>_<）反而一直在愧疚跟自責中徘迴只能又累又痛的縮在床上~所以想請問誰是否有什麼換藥建議？（有服用SSRI）謝謝--e'g elska tig--好的><因為最近不想看醫生想說先做好準備謝謝您!>< 前幾天大概8:00就會吃史蒂諾斯，即使什麼都不做的躺在床上還是可以醒到凌晨4:00（有睡著的話），沒睡著就是一直都沒睡。導美睡我吃過但對我來說太短效><謝謝您！健康得眠如果我沒理解錯誤的話就是宜眠安呦!但我沒辦法分辨口乾舌燥是不是副作用因為我本來就很會口渴XD 現在希望史蒂諾斯讓我忘記偏偏起不了作用：(人生更苦XD但有些事情想忘記XD\",\n",
       "  0],\n",
       " ['看了很久還是沒好不是醫生的問題是我的問題我想換醫院了----Sent from BePTT on my HTC U12 life--', 0],\n",
       " ['很亂，心中亂成亂一團。這些天我終於比較適應L的新工作室環境，可是沒有適應教練的高強度訓練。因為膝蓋反覆疼痛無法做有氧，加上我飲食失調的症狀還沒完全消失，教練說那就只好拉高上課頻率和強度，今天是連續上課的第二天，酸痛越來越多，很累。明天還有最可怕的間歇性訓練，想到就很崩潰。可是身體並不是不能承受，只是心理上還在適應。不知道該怎麼描述現在的狀況，全身酸痛、寫字手抖、不定時暴食、腸胃不適、內心一片混亂，覺得有點難以承受:(但是又不想放棄...對於一個從來不運動的運動白痴來說，可以撐過一次的間歇性訓練是令人感動的QQ雖說我完全不知道自己是怎麼度過那次上課...有點想吐，晚餐想吃已經快要一年沒吃的麵攤。--',\n",
       "  0],\n",
       " ['辭職後發現工作好難找但不辭職在繼續下去完全不會好轉只會越來越糟糕辭職後現在整個強迫跟憂鬱好轉想回到一般生活開始工作也想朝自己一直想做的工作前進但發現好難又開始後悔自己是不是不應該辭職即使不是想做的，即使發病在怎麼嚴重都應該撐下來，至少能有收入雨好大心好空--謝謝你其實應該?是時好時壞，因為家裡環境的關係所以想趕快工作讓自己減少在這個環境的時間...',\n",
       "  0],\n",
       " ['*借男友帳號發文男友來自單親家庭，自從買房後，男友就有在計畫要跟他媽媽出櫃，其實他當初跟我在一起，就跟他媽說他有交女友，只是一直不給她看，經過這些時間，他媽媽也聽過鄰居說：看過你兒子在樓下跟另一個男生',\n",
       "  0],\n",
       " ['好久沒發文了最近的生活似乎是安逸又痛苦的不是很劇烈，但就像是被好幾條蟲啃咬著心臟一樣嘛...不過，值得開心的是~我他媽終於從學店畢業啦！！（灑花）拿到證書的當下還是有點感動的...雖然比別人慢了六年（醜哭）雖然目前還是要繼續當家裡的寄生蟲，對不起orz悲觀的想法真的很難改善從心裡生病的那刻起覺得人生好像不斷在累積污點，不斷在麻煩別人覺得自己是個負價值的垃圾跟人接觸總是畏畏縮縮的深怕別人發現我的過去，知道我是多麼沒用已經忘記正常的社交到底應該是怎麼樣的了...我總是覺得別人都很好，就我最爛但如果對方是跟我擁有一樣經歷的人，我卻會認為他的未來還是有希望的我總是恐懼，卻沒辦法認知到別人也是有恐懼的時候或許這就是為什麼說得容易，做起來卻很難？自己要去執行的時候恐懼無限增長明明就只是一些小事，像是念書明明是有益無害的事情，卻總是選擇逃避堆疊出現在沒用的我真的好想要改變好想變回一張白紙，好想把過去塗得烏漆嘛黑的部份全部撕掉但人生就是這麼狗屎爛蛋的事，無法重來現在就登出的話，我的人生真的就只剩那些狗屎爛蛋了，所以還是先不現在的目標是每天只要能夠製造一點點價值就好或許痛苦就能消除那麼一點點吧很感謝有p板這麼一個能讓人隨意抒發的地方願我們都能找到消除痛苦的方法（除了登出人生以外的）-----Sent from JPTT on my iPhone--謝謝：）只能練習改掉這樣的想法了QQ以前爛沒關係，以後能變好的！',\n",
       "  0],\n",
       " ['知道妳有很多情緒要處理所以非到必要我是不找妳的認識也7年起跳了吧其實幾年我真的記不得了妳妹大學時跟渣男在一起為了救妳妹妳一直問我要不要認識妳妹啊一直說，你不是最喜歡豐滿的嗎我妹有G耶我笑了我推拖了好幾次因為她有男友啊，就算是渣男總也是男友啊我有時會想妳只知道她男友是渣男啊妳又不知道我也有可能會對妳妹不好啊這樣好像把妳親妹推火坑吧（笑）後來還是認識了妳妹生日的那天我們去青春譜唱歌我還記得妳特地提醒我要買個蛋糕在妳妹心中會很加分妳們姐妹都滿漂亮的，身材又好我連看都不太敢看妳們其實後來妳妹也說過要當我2個禮拜的女友當然是跟渣男分手後啦但在一起的情況也太好笑是她情緒崩潰住院出院後的一次約會而已也只僅止於抱了那麼一下她的病妳的病讓我也不太敢再把負面情緒丟給妳昨晚實在是受不了了才問妳可不可以陪我講講話我何其有幸能被身為醫師的妳看中想介紹妳妹給我認識又何其有幸跟妳們都曾有過深交好希望能回到初識時我能控制我的病能一直溫暖的看著這世界的一切能告訴自己一切會越來越好那時我剛30妳們都還20幾那時多麼青春無悔的時刻妳說，不然，妳來我家帶我去辦住院的事可妳那摸聰明的人妳又怎會不知住院其實幫不了我了我的問題不是住院可以解決的妳願意提出這個提議我很感動也很感謝只是好像小說翻到最後幾頁了只剩下薄薄的一小篇我家裡的事不解決我的病也就不可能會好我也不可能再交女友了叫我一輩子養條貓狗過一生其實真的太殘忍了我還是不太會找妳下一次大概又是嚴重發病的時候吧--',\n",
       "  0],\n",
       " ['下午在別處看到新聞，又觸發焦慮。又苦惱到一直猶豫了。滑104看到大公司有說訓練課程的，我馬上渾身不舒服，我真沒上進心...。我完全不想。就只想當個隱形人，但這種最容易被裁員。就想當簡單的人。遲疑不敢說滿。這種回答算糟吧？太多年了，沒用嗎？給你八個月失業休息夠嗎？--',\n",
       "  0],\n",
       " ['我有一個心結從十年前就在了那時十八歲的我被喝醉的爸爸性侵了這時間只有我媽在家但我媽當下只告訴我爸爸把你當成我了而她也一直隱瞞爸爸他的所作所為只說喝醉抱著我這十年大多數時間我不是在酗酒就是在自殺的路上中幾次幾次的被醫院救回來直到我結婚生了小孩開始有依靠有被需要的感覺我覺得我慢慢的好像好多了但在三年前我爸又開始賭博了不知道為什麼我又開始傷心難過恨他了因為當初一直告訴自己他回歸正途了試著原諒他吧結果我就在臉書打原諒一個人的理由不見了是不是能繼續恨了？我媽問我再說我爸嗎我說對 我媽就把這對話截圖給我爸那時候我晚上睡覺了我爸一直打給我但我沒聽到等到早上起來時看到又看到他在我們家30人的大家族裡說我當初也只是不小心喝醉抱著你你有必要死抓著這事情不放過我嗎真的這麼恨我我去自首可以了吧？當下我除了顫抖眼淚我不知道我還能做什麼冷靜一陣子後 我決定告訴大家把那天他性侵我的過程細細描寫在群組給大家知道可是等來的是一群已讀阿伯密我 我原來你之前喝酒吃藥是這樣 我沒想到你這幾年過這麼苦 但為了爸爸也老了給他點尊嚴吧？？？？？？！！！！！不要尊嚴不要面子的人是他耶這麼丟臉羞恥的事我都不敢也沒曾想過要提起那之後這兩三年每逢逢年過節我都提前或往後的避開他才回去但上禮拜聽說他喝醉跟我哥又差點打起來那幾天我情緒都很崩潰前天喝個爛醉回家昨天早上我姐夫就罵我說你到底有什麼心結需要這樣吃藥喝酒我說我爸他說 拜託都這麼久了 你不能放過自己嗎？呵呵呵為什麼大家都要我放過自己要我打開心結？能的話我比誰都還想放過自己打開心結但這些事情總是歷歷在目總是夢裡會夢到我也不想啊 昨天吃了安眠藥加情緒藥物8顆試著要睡覺可是眼淚從他那句話開始就沒停過後來三小時後我又吃了四顆撫緒一個悠樂丁但想死的念頭還是一直在我一直走到廚房拿起刀子又放下想到自己答應女兒不能再自殺我就背起包包來到台大醫院了經過急診醫師詢問再請精神科醫生聊天知道狀況後給我打了一針終於半夜三點我有想睡的念頭了現在的我起來了 情緒穩定了一點但很感謝我自己 還知道要來醫院不然我真的不知道我會幹出什麼事情來拜託不要一直要求我們放過自己 要求我們這些就很像跟坐輪椅的人說 來 站起來你可以的--真的是幹話我姐很愛我 知道我姐夫講這個時跑去罵他了 還一直進房間抱我可是我還是一直掉眼淚不提起我都還好 只是有時候想到夢到 當天我就會需要一點酒精就是因為阿公阿嬤老了 我不想去搞這麼大 當初我找我姐我媽求救 卻都要我選擇放下....真的哭一整天 今天眼皮超雙哈哈是 沒人肯站出來幫助我保護我我不面對我爸兩三年了多次了 只是我覺得我還是找不到好的放過自己的方法05/05 11:37我真的為了她們而活了..是啊而且又是自己曾經愛的家人5/05 12:06謝謝你 睡一覺我好多了謝謝你 我好多了我媽有嘗試彌補（在今年二月我被我前夫家暴時 跑來找我 道歉說當時她也慌了不知道該怎麼做 所以一直沒動作 但這道歉太遲了 十年 我想我要的不是道歉了吧......是的 所以我媽說要找我爸一起出來去台安醫院把心結打開我不是很想 因為我並不覺得他們知道我的難過跟糾結 只知道要跟我道歉罷了好方~？剛剛我幫我姐把洗衣機衣服拿去烘結果發現一根管子我問她那是什麼她說是我姐夫吸鼻子的我就放在廚房台我姐要我拿給他 我說不要 然後我就進房間了結果我姐打了這些https://i.imgur.com/tKBiAW7.jpg真的是幹話我姐很愛我 知道我姐夫講這個時跑去罵他了 還一直進房間抱我可是我還是一直掉眼淚不提起我都還好 只是有時候想到夢到 當天我就會需要一點酒精就是因為阿公阿嬤老了 我不想去搞這麼大 當初我找我姐我媽求救 卻都要我選擇放下....真的哭一整天 今天眼皮超雙哈哈是 沒人肯站出來幫助我保護我我不面對我爸兩三年了多次了 只是我覺得我還是找不到好的放過自己的方法05/05 11:37我真的為了她們而活了..是啊而且又是自己曾經愛的家人5/05 12:06謝謝你 睡一覺我好多了謝謝你 我好多了我媽有嘗試彌補（在今年二月我被我前夫家暴時 跑來找我 道歉說當時她也慌了不知道該怎麼做 所以一直沒動作 但這道歉太遲了 十年 我想我要的不是道歉了吧......是的 所以我媽說要找我爸一起出來去台安醫院把心結打開我不是很想 因為我並不覺得他們知道我的難過跟糾結 只知道要跟我道歉罷了好方~？好的謝謝所以我努力吃藥控制情緒......那天我睡覺我媽在陽台才發生這樣的事所以我努力吃藥控制情緒......謝謝 我會努力渡過的是 所以我媽說要去台安找家醫科三個人把心結解開 但我只相信馬階諮商呂醫師 她一直不肯 我媽的朋友告訴我 學著跟父母拒絕 因為只有我的醫生了解我保護我',\n",
       "  0],\n",
       " ['https://i.imgur.com/BptF9wl.jpg工作22年生了這個病也應該有10幾年從一開始的自殺到現在比較好只要吃安眠藥可是也帶來了一些大病沒有小病不斷的症狀今天受不了提出留職停薪的要求不知道公司接受嗎還是會資遣我--',\n",
       "  0],\n",
       " ['1.你不用討好別人2.工作不是拿來交朋友的3.有交到是不可多得的幸運3.離職就不認識了4.沒有人帶我 我已經很厲害了5.死線是死的 人是活的6.反正書裡都有答案7.反正我還有寶雖然還是不懂為什麼要錄取我反正最糟糕就是被fire就就可以領失業補助了那也不錯嘛大不了再窩回設計圈呀想好後路就不會那麼焦慮了--',\n",
       "  0],\n",
       " ['<<< 屬於自己的心理健康講座：免費客製化主題由您配 >>>想在自己舒適的場所，舉辦一場專屬於你的心理健康講座嗎？中華身心健康促進暨研究協會承接衛生福利部LGBTI族群心理健康促進計畫，推廣多元主題講',\n",
       "  0],\n",
       " ['今早作了一個夢，夢中夢見了一個姨婆，很久不見，在夢裡他很熱情的招呼 著我和我爸。剛起床時，心情還不錯，但出了房間門口，心情又變得稍稍的 不好。 因為我爸昨夜又去喝了個爛醉，直接躺在地板上睡覺，有這樣的爸爸，真的 很糟，但他有進步的是，至少沒有鬼吼鬼叫影響我睡眠，這是讓我慶幸的。 於是我在想，真的有報應這麼回事嗎？或許我當他的兒子，是代表我這輩子 是來還債的，所以這輩子才會受盡欺凌，也沒辦法一個人過好自己的生活， 甚至覺得沒有家人會很恐懼，但有這樣的家人也讓人恐懼，很多事情都無能 為力，也無法選擇。我在想，或許是老天爺怕我變有錢以後，會拋棄我爸， 所以才讓我事事不順，讓我找不到自由的出口，也只有讓我變窮，我才會跟 我爸待在一起。 但我已經不相信所謂的報應之說了，因為再怎麼看，做了壞事的人，也沒看 過他們有哪天發生事情的？他們還是一樣過得好好的，根本沒有報應這回事 。 再怎麼想都沒有用吧！我爸就是這樣，酒鬼跟吸毒者一樣，根本沒有信用， 一看見酒或毒品，就完全不管之前所說的承諾，所發的誓，就跟不存在一樣 ，通通拋到腦後，喝完以後又再跟我抱怨身體這裡痛那裡痛，我又不是醫生 ，我哪有辦法？ 所以想想，我這輩子的命真的很苦，生在一個沒錢的家，然後又要跟機歪的 家人生活，真的是很慘。 人活在世上，只有有錢才是硬道理，其他都是假的。--我們都會期望現實世界中，有個人可以拯救我們，幫助我們面對困難與解決問題，但現實生活中並沒有人會來拯救我們。我們能夠做的，就只有每天不斷的犯錯與尋找答案。--',\n",
       "  0],\n",
       " ['如往常的今天回診諮商聽到醫生說「妳真的感覺好多了，笑起來比較真」那個瞬間其實我哭了覺得被認可了很開心，於是哭覺得這句話太溫暖了，於是哭不想哭的卻莫名地鼻頭一酸、眼眶濕潤「啪嗒」手背下雨了我還是想成為小太陽真真正正好的小太陽照亮這個世界，這個讓我很難愛得了，但我正努力去愛的世界照亮他的黑暗，那個不管好的壞的，我卻都非常喜歡的那個他--',\n",
       "  0],\n",
       " ['我的粉絲頁：https://www.facebook.com/chch1919自從憂鬱之後做什麼都不順利憂鬱的心態上也很難改變再加上之後的幻聽來述說憂鬱/思覺失調對我日後工作上甚至找工作上的影響影片：https://youtu.be/36E0CIudIo8此文同發於精神疾病版--',\n",
       "  0],\n",
       " ['近期會寫出很多故事不會寫的很完全 但應該都能看出個大概很久很久以前在網路上聊色的地方有一個文筆還不錯的男生用文章騙了很多很多女生（同時交好幾個女友，騙女生沒女友來打砲）有小至17歲被他騙當女友拿走第一次的也有快30歲的女生，他當時應該是20歲左右光我在網路上認識的女生朋友大概就有5個跟他發生關係過有點才華的男生很吸引人所以他利用這點開了粉絲團再選了一個女生很多的討論區當板主洗白在很多很多年前他還不紅的時候其實我就不太喜歡這個人我知道他講的很多東西都是虎洨的自以為聰明設下很多道防火牆以為怎麼玩火都不會燒到他身上這個人叫做1010有一次有一個也很想紅的水底生物水底生物很討厭1010就在那個女生很多的討論區發了一篇文影射1010的一些事這時我們一些知道事情真相的人就在推文聊起來夜裡有一個女生寄信問我你到底知道些什麼我一開始擔心他是1010派來探口風的臥底就跟她打了幾分鐘啞謎到後來確定她身份後，才卸下心防跟她聊天她跟我說她是1010的女友，只是1010說自己算半個公眾人物，所以感情不能公開她很好奇為什麼我們要在那篇文章下那樣子討論1010約莫聊了半小時我另一個女生朋友敲我，問我在乾嘛我說我在跟1010的女友聊天那女生突然很激動的問我怎麼可能，你不要亂講我說真的啊，我真的在跟1010的女友聊天那女生就要我把1010女友的賴給她她們互相聊了以後對了很多事才發現原來他們都是1010當時的女友除了她們外，還有第三個女友她們很生氣所以就準備了一兩天，把這件事公開我當時因為發文量大不想被他的粉絲酸，所以我躲在幕後於是一篇一篇回文徹底的把這件事掀開有很多人寫信給最大的那個女友講了也有被他約跑的事粗略算一算大概有60幾個左右只是有的有成有的沒成後來這件事鬧上了新聞1010就辭了板主那當時有個女生問1010還好嗎他說，還好啊，還是我說不好的話，妳要來陪我嗎？當我們看到這截圖時，真的搖頭事情都這樣了還想約啊又後來，我跟他最大的女友在討論我設想了很多種可能他為了保住他的名聲他的帳號他的粉絲團誓必會有反撲我猜到他會說大女友精神狀況有問題其實很早就想分手了只是怕她自殺果然後來就有聽他跟他朋友在講只是我已先一步在推文把推說大女友是精神病這梗先破梗了所以他後來在ptt就比較沒發文了至少在ptt就沒辦法再這樣騙下去（他粉絲團本來有快1萬人，利用粉絲團看臉篩人喇妹）那當時其實我是有點害怕的我不想與人為敵，也非眼紅別人能這樣騙砲打砲會選擇跳進去，就剛好是我朋友被騙砲了我遇到了能除害的機會所以就做了當然也因此就被他跟他的腦殘粉恨上我很愛惜我的帳號我很怕被他們口水噓淹沒但我有我要守護的正義正義需要力量我沒想過是不是我的力量只是一個笑話幸好後來結果是好的我以為我推倒了一個大魔王但後面平靜了幾年魔王又有了繼承者（待續）--',\n",
       "  0],\n",
       " ['開始停速悅的這幾天我還是會吃安立平總覺得現在除了心悸手抖頭很重以外一直還有個在耳邊敲打小軍鼓的聲音但也一直有做夢一直夢到我還沒休學前深夜自己在lab裡埋頭苦幹的時候很無助 不知道怎麼段時候醒來的時候還會驚嚇的想我是不是還要去學校應該睡得者吧大家晚安--',\n",
       "  0],\n",
       " ['回想起第一次接觸韓劇是國小的時候~就是當時最火紅的來自星星的你！但本篇沒提到因為我記得我沒看完哈哈上榜的都是我有看完整部~然後當下覺得很愛的以下部分介紹參考維基百科（想介紹給大家但實在有一點點忘記劇情',\n",
       "  0],\n",
       " ['「人會輕信與盲從，通常處於受傷或脆弱時刻」。在這資訊爆炸的時代中，每天都擁有上千條的資訊在流竄，媒體為了得到更高的點擊率不惜寫出聳動的標題，甚至製造出假新聞；政治人物為了得到支持， 也不斷製造話題、造',\n",
       "  0],\n",
       " ['對L很明顯地投射，我心中一直有個理想的某角色，我將這個渴望角色投射在L身上，可是今天被冷冷對待了，很難受很難受。我覺得自己這陣子明顯進步不少，可是L都沒有說什麼，挺令人失落的:(很清楚治療關係是特殊營造出來的，L其實也有好的不好的，我一下子將情感投射完全依賴L，一下子告訴自己這只是我的移情，我很混亂。我在理性與感性中拉扯。想起L說過他想成為我的夥伴，想要陪我去看我經歷的事情，可是他沒有說要當我的oo，是我不該有這樣的投射移情。我錯了。--',\n",
       "  0],\n",
       " ['酣樂欣 也就是triazolam我吃這顆只要稍微一過量(三顆以上) 會嚴重頭痛 然後肩膀痠 雙眼昏花 走路不穩讓我以為我感冒了 躺在床上更睡不著但FM2我吃過量也沒什麼感覺 我身體對FM2的耐受性似乎還滿強的你們吃這棵也會頭痛嗎?我在想是我拿到的triazolam不純 還是本身身體就跟這藥不合--',\n",
       "  0],\n",
       " ['不知道會不會比較好今天又拿了一堆藥有些已經數不清了大家晚安繼續失眠https://i.imgur.com/O4knb8e.jpg--', 0],\n",
       " ['你們好嗎？依舊被煩人的隔壁主管亂鬧焦慮又憂鬱但今天想好好的認真一下再過兩天就週末了累累的 希望可以維持少吃點藥--', 0],\n",
       " ['疲累的時候會記得要吃藥哀鳳SE2讓我不想打字因?一直打錯字！鍵盤太小很煩用語音方便但容易太口語想著「好累好煩好難過」的時候眼淚都要掉出來的時候就會想起「對了晚上的藥我還沒吃」「應該只是沒吃藥造成的吧！」然後等情緒慢慢過去又花錢了 買了化妝品跟香脂--',\n",
       "  0],\n",
       " ['此刻的我，胸悶劇烈，不知為何引發？十年之久，馬齒徒長， 大學重考也許注定悲劇。大學時勵志改變自己，直到去年為止還在改變自己，哈哈，根本一則笑話，三十而立，發現已經無能為力，一食無缺的我根本庸人自擾，比我悲慘的人多的是，有些人依然可以努力過活，有些人甚至跌倒再爬起，而我呢？ 是我想要的太多了嗎？我想得到比吃飽再多一點東西，這樣太貪了嗎？也許是吧！過去的遺憾還是時常伴隨，我不知道如何緩解，時間過再久都無法解決傷痛，我選擇逃避不去想，是阿！不去想就沒事了，想到了就是萬分痛苦，記憶已經深刻在腦袋裡了其過了這晚，明天起床沒事了，再過幾天，也許會覺得自己沒病了，跟大家一樣。或許因為天氣，各種資訊，讓我感覺自己魯到炸，心情就跟著炸裂吧這樣的循環似乎很久了，何時可以停止呢？--',\n",
       "  0],\n",
       " ['花卉瓜果盛放是那?香甜他們美的像一生沒有受過傷而美是一種機運看著枝頭上的鳥兒多麼五彩繽紛他們一定有某種我們無法觸及的快樂所以才這麼美艷你的瞳孔是深黑的望進去像無盡的深淵你一定有個哀慟的心臟所以我才無法了解你——我的ig康復日誌po_ya_chan--',\n",
       "  0],\n",
       " ['怎麼婉拒工作邀約一開始勉強自己去面試後來又要希望對方不要錄取自己最後上了還要婉拒對方心很累-----Sent from JPTT on my iPhone--',\n",
       "  0],\n",
       " ['曾經經歷過霸凌 現在還是讓我無法忘記或許是在那時候 我知道了什麼叫憂鬱 也是我第一次有想自殺的念頭但我沒有對任何人說近年來感覺自己情緒起伏大很容易生氣 也很容易沮喪 容易哭變得自卑 覺得自己很沒用開始',\n",
       "  0],\n",
       " ['什麼都沒有。好痛苦，好痛苦。他說離開的話至少要跟他說，於是開始寫告別信，寫的很卡，跟現在的頭腦一樣。好痛苦，好痛苦，好想結束這一切，可是寫著寫著似乎又有什麼留戀了。想起家裡還有備用的千憂解，趕快吃了躺平，希望痛苦趕快散去，希望明天不要吐得太厲害。--',\n",
       "  0],\n",
       " ['今天是妳生日喔還記得嗎？我們曾講好過以後都要一起過生日的但我生病所以知道自己配不上妳只敢一直以好朋友的身份陪著2008年認識妳，跟妳還有妳妹一起去九份也是改變我人生的一天2008那年發生對我來說人生的幾件大事如果當時沒遇到那些事可能我更早就死了也不一定每年我都記得妳的生日因為我們只差了幾天而已還記得出去第二次時，我才驚訝妳竟然是台大的妳微笑的對我說妳以為我早就知道了，因為其實看ip就知道了啊還記得妳跟妳妹在我跟德後面一直用廣東話聊天的時候我直接轉過頭問妳們無事獻殷勤非奸即盜的廣東話怎麼講妳跟妳妹異口同聲的用廣東話講給我聽還記得我去台北找妳時，妳說妳有時很閒要我多約妳出去還記得我家這有海水倒灌警報時，妳立刻傳簡訊問我沒事吧還記得有次接到妳電話一接起來妳就哭了跟我說怎麼辦，妳媽媽生了重病我完全不知道能說些什麼來安慰妳還記得妳妹要結婚那時，妳問我要不要去參加妳說妳有跟妳媽說我跟德的事妳媽也想看看妳在台灣交到的這些朋友我的人生不知道為什麼走到這一步仿佛好像又聽見2008年後來幾次出去玩時德偷偷說，你把她追起來那你就變成醫生公了醫生公是啥鬼啊（翻桌）我瞪了德一眼我又不是看錢看很重的人我只是覺得妳是一個相處起來讓人覺得很舒服的女生罷了（大概是我這輩子認識的女生中，前兩名的存在吧）有一點點喜歡但又沒有喜歡到我能對抗我的病的那種喜歡我想面對妳時我是自卑的吧我也覺得自己應該沒辦法好好照顧妳所以最後還是變成了這樣每年淡淡的祝妳生日快樂的朋友希望妳可以一直開開心心的幸福下去偶爾我會去偷查妳發文所以妳結婚了，生小孩了我都知道的喔我在遠方靜靜的替妳開心著我硬碟壞了，所有的合照都不見了但我腦袋還記得妳的聲音我也還記得我一直都還記得謝謝妳那年七夕情人節跟我們出去那給了我離開我單戀了快11年的女生的勇氣我才知道原來我是可以去喜歡別的女生的我才知道或許換個方向我不一定要一輩子單戀小莉下去好久好久的事了12年了呢生日快樂我們都要好好的希望明年我也還能祝妳生日快樂--',\n",
       "  0],\n",
       " ['好像又要掉回去掉回去那個深不見底的地方要靠藥物靠傷害自己才能勉強繼續維持生活不過也還好大概只是最近比較掉下去一點罷了整體來說跟過去比起來還是不糟的不過最近的掉下去都是憤怒亢奮又無力發自內心的恨與絕望--',\n",
       "  0],\n",
       " ['很努力地壓抑不要依賴醫生不要依賴任何人不要流淚眨眼把眼淚都收回去忘了好多事忘記帶安全帽下班忘記帶皮夾下班忘記帶鑰匙下班洗衣服忘記倒洗衣精忘了關包包*N忘了關車廂*2忘了帶東西*N忘了吃什麼*N忘了做什麼*N忘了該做啥*N忘了要吃藥*N忘了吃過藥沒有*N忘了把東西放哪*N開會/講座忘了帶筆*N把晶片卡插在電腦上忘記拔*N騎車恍神闖紅燈差點撞上車連醫生問我一天共要開多少劑量的藥都只回答早上吃的量假日就是昏睡壹整個白天到了晚餐時間才能清醒等到十點 準時吃藥睡覺是焦慮嗎是憂鬱嗎沒差 人生短短的 很快就過去了--',\n",
       "  0],\n",
       " ['名符其實睡了一整天大概是22個小時剩下的2小時是中間起來吃晚餐彷彿昨天是整個消失在月曆上了爆睡之前是和朋友去喝酒遇見了三年多未聯絡的朋友總覺得在三年多前和對方是「很好的朋友」只是不知道為什?就失聯了但聚會一直到最後突然意識到從頭到尾都是自己的一廂情願失聯不是什麼偶然的事件而是必然的結果不禁覺得自己十足可悲停止自作多情吧你無趣、平庸又廉價--',\n",
       "  0],\n",
       " ['並不是真的想要死是因為活不下去盡力找尋活著的方法有一天已經用盡了力氣就是現在沒有了活下去的本能接下來會怎麼樣--', 0],\n",
       " ['先從這說起兩年前因為交了一個跟我一樣童年有過被情緒暴力 再加上都是獨生子女難免內心有些不健全 的男友例如吵架的時候會自殘 平常會有點憂鬱的傾向這些都很淺層的敘述 但沒辦法在這深究總之可能因為我跟他太',\n",
       "  0],\n",
       " ['原本兩點多就要躺床了結果三點才床最後滾到六點才睡著還一邊用手機一邊找工作經過一個禮拜的度假腦袋關機休息後的清醒害我亢奮到不用睡覺...結果呢 只睡了四小時十點就起來了想繼續睡但還是睡不著腦袋好多想做的事(整理家裡 曬棉被!!)????????到底是不是躁鬱症阿...--',\n",
       "  0],\n",
       " ['把家裡燈都關了躺在床上，瞪著天花板，鬧鐘想著明天的流程：早上6點起床、寫好對位法作業自己扛著器材出門、買樂手評審的飲料餐點到了學校得搬椅子、譜架…等等事前準備想到這裡，我發現，自己還真的是個孤獨的人包覆在黑暗之中，大字型的躺在床上「算了，不過是個音樂會」睡吧--',\n",
       "  0],\n",
       " ['前陣子透過D卡聯繫上一個柯伊大，在這我稱呼他為老師(雖然私底下沒有喊他老師本靈(可以理解為累世靈魂，通常由最強的那個為主控，所以祂不一定是品性最好的，只是某一世力量最強的。祂會影響著我們的直覺，第六感',\n",
       "  0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = toList(train)\n",
    "val = toList(val)\n",
    "test = toList(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df #its list [['text1',label],['text2',label],...]\n",
    "        self.len = len(self.df)\n",
    "        self.maxlen = 250 #限制文章長度(若你記憶體夠多也可以不限)\n",
    "        self.tokenizer = tokenizer  # we will use BERT tokenizer\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        origin_text = self.df[idx][0]\n",
    "        text_a = self.df[idx][0]\n",
    "        text_b = None  #for natural language inference\n",
    "        #label_tensor = None #in our case, we have label\n",
    "        label_id = self.df[idx][1]\n",
    "        label_tensor = torch.tensor(label_id)\n",
    "        \n",
    "        # 建立第一個句子的 BERT tokens\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_a = self.tokenizer.tokenize(text_a)\n",
    "        word_pieces += tokens_a[:self.maxlen] + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "        \n",
    "        if text_b is not None:\n",
    "            tokens_b = self.tokenizer.tokenize(text_b)\n",
    "            word_pieces += tokens_b + [\"[SEP]\"]\n",
    "            len_b = len(word_pieces) - len_a\n",
    "            \n",
    "        # 將整個 token 序列轉換成索引序列\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
    "        if text_b is None:\n",
    "            segments_tensor = torch.tensor([1] * len_a,dtype=torch.long)\n",
    "        elif text_b is not None:\n",
    "            segments_tensor = torch.tensor([0] * len_a + [1] * len_b,dtype=torch.long)\n",
    "            \n",
    "        return (tokens_tensor, segments_tensor, label_tensor, origin_text)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = MyDataset(train, tokenizer=tokenizer)\n",
    "valset = MyDataset(val, tokenizer=tokenizer)\n",
    "testset = MyDataset(test, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MyDataset(Dataset):\n",
    "#     data_len = len(Dataset)\n",
    "#     maxlen = 250\n",
    "#     text_a = Dataset['Content']\n",
    "#     origin_text = Dataset['Content']\n",
    "#     text_b = None  #for natural language inference\n",
    "#     label_id = Dataset['Label']\n",
    "#     label_tensor = torch.tensor(label_id)\n",
    "\n",
    "#     # 建立第一個句子的 BERT tokens\n",
    "#     word_pieces = []\n",
    "#     for i in range(len(text_a)):\n",
    "#         word_pieces += [\"[CLS]\"]\n",
    "#         tokens_a = tokenizer.tokenize(text_a[i])\n",
    "#         word_pieces += tokens_a[:maxlen] + [\"[SEP]\"]\n",
    "#         len_a = len(word_pieces)\n",
    "#         if text_b is not None:\n",
    "#             tokens_b = self.tokenizer.tokenize(text_b)\n",
    "#             word_pieces += tokens_b + [\"[SEP]\"]\n",
    "#             len_b = len(word_pieces) - len_a\n",
    "            \n",
    "#     # 將整個 token 序列轉換成索引序列\n",
    "#     ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "#     tokens_tensor = torch.tensor(ids)\n",
    "    \n",
    "#     # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
    "#     if text_b is None:\n",
    "#         segments_tensor = torch.tensor([1] * len_a,dtype=torch.long)\n",
    "#     elif text_b is not None:\n",
    "#         segments_tensor = torch.tensor([0] * len_a + [1] * len_b,dtype=torch.long)\n",
    "\n",
    "#     # 將 tokens_tensor 還原成文本\n",
    "#     tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "    \n",
    "#     print('token:\\n',tokens,'\\n')\n",
    "#     print('origin_text:\\n',origin_text,'\\n')\n",
    "#     print('tokens_tensor:\\n',tokens_tensor,'\\n')\n",
    "#     print('segment tensor:\\n',segments_tensor)\n",
    "#     return (tokens_tensor, segments_tensor, label_tensor, origin_text, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 5204, 4495,  ..., 5442, 8024,  102],\n",
      "        [ 101, 7464, 4852,  ...,    0,    0,    0],\n",
      "        [ 101, 3297, 6818,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 2407,  ..., 7076, 1164,  102],\n",
      "        [ 101, 3315, 6716,  ...,    0,    0,    0],\n",
      "        [ 101, 2769, 1348,  ...,    0,    0,    0]])\n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\"\"\"\"\n",
    "create_mini_batch(samples)吃上面定義的mydataset\n",
    "回傳訓練 BERT 時會需要的 4 個 tensors：\n",
    "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
    "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
    "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
    "- label_ids       : (batch_size)\n",
    "\"\"\"\n",
    "#collate_fn: 如何將多個樣本的資料連成一個batch丟進 model\n",
    "#截長補短後要限制attention只注意非pad 的部分\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    # 訓練集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "        \n",
    "    # zero pad到該batch下最長的長度\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors,batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape,dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "\n",
    "# 初始化一個每次回傳 batch size 個訓練樣本的 DataLoader\n",
    "# 利用 'collate_fn' 將 list of samples 合併成一個 mini-batch\n",
    "BATCH_SIZE = 91\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,collate_fn=create_mini_batch,shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=BATCH_SIZE,collate_fn=create_mini_batch,shuffle=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE,collate_fn=create_mini_batch,shuffle=False)\n",
    "\n",
    "data = next(iter(trainloader))\n",
    "tokens_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "print(tokens_tensors)\n",
    "print(segments_tensors)\n",
    "print(masks_tensors)\n",
    "print(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name      module\n",
      "--------------------\n",
      "bert      embeddings\n",
      "bert      encoder\n",
      "bert      pooler\n",
      "dropout    Dropout(p=0.1)\n",
      "classifier Linear(in_features=768, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "NUM_LABELS = 2\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "name      module\n",
    "--------------------\"\"\")\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    if name == \"bert\":\n",
    "        for n, _ in module.named_children():\n",
    "            print(\"{:10}{}\".format(name,n) )\n",
    "    else:\n",
    "        print(\"{:10} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cublas runtime error : the GPU program failed to execute at /opt/conda/conda-bld/pytorch_1556653215914/work/aten/src/THC/THCBlas.cu:259",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m         )\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 )\n\u001b[1;32m    484\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         )\n\u001b[1;32m    404\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     ):\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/trainEnv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cublas runtime error : the GPU program failed to execute at /opt/conda/conda-bld/pytorch_1556653215914/work/aten/src/THC/THCBlas.cu:259"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\",device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    correct = 0\n",
    "    #total = 0\n",
    "    train_loss , val_loss = 0.0 , 0.0\n",
    "    train_acc, val_acc = 0, 0\n",
    "    n, m = 0, 0\n",
    "    model.train()\n",
    "    for data in trainloader:\n",
    "        n += 1\n",
    "        tokens_tensors, segments_tensors,masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "        # outputs 的順序是 \"(loss), logits, (hidden_states), (attentions)\"\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #get prediction and calulate acc\n",
    "        logits = outputs[1]\n",
    "        _, pred = torch.max(logits.data, 1)\n",
    "        train_acc += accuracy_score(pred.cpu().tolist() , labels.cpu().tolist())\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    #validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in valloader:\n",
    "            m += 1\n",
    "            tokens_tensors, segments_tensors,masks_tensors, labels = [t.to(device) for t in data]\n",
    "            val_outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "            \n",
    "            logits = val_outputs[1]\n",
    "            _, pred = torch.max(logits.data, 1)\n",
    "            val_acc += accuracy_score(pred.cpu().tolist() , labels.cpu().tolist())\n",
    "            val_loss += val_outputs[0].item()\n",
    "\n",
    "    print('[epoch %d] loss: %.4f, acc: %.4f, val loss: %4f, val acc: %4f' %\n",
    "          (epoch+1, train_loss/n, train_acc/n, val_loss/m,  val_acc/m  ))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2060'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainEnv",
   "language": "python",
   "name": "trainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
