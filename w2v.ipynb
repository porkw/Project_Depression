{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from gensim.corpora import WikiCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load wiki data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-06 16:36:33,815 : INFO : 已處理 10000 篇文章\n",
      "2020-10-06 16:37:02,783 : INFO : 已處理 20000 篇文章\n",
      "2020-10-06 16:37:28,214 : INFO : 已處理 30000 篇文章\n",
      "2020-10-06 16:37:53,893 : INFO : 已處理 40000 篇文章\n",
      "2020-10-06 16:38:20,326 : INFO : 已處理 50000 篇文章\n",
      "2020-10-06 16:38:46,831 : INFO : 已處理 60000 篇文章\n",
      "2020-10-06 16:39:12,152 : INFO : 已處理 70000 篇文章\n",
      "2020-10-06 16:39:37,806 : INFO : 已處理 80000 篇文章\n",
      "2020-10-06 16:40:01,823 : INFO : 已處理 90000 篇文章\n",
      "2020-10-06 16:40:25,385 : INFO : 已處理 100000 篇文章\n",
      "2020-10-06 16:40:59,233 : INFO : 已處理 110000 篇文章\n",
      "2020-10-06 16:41:24,203 : INFO : 已處理 120000 篇文章\n",
      "2020-10-06 16:41:54,072 : INFO : 已處理 130000 篇文章\n",
      "2020-10-06 16:42:23,217 : INFO : 已處理 140000 篇文章\n",
      "2020-10-06 16:42:50,891 : INFO : 已處理 150000 篇文章\n",
      "2020-10-06 16:43:20,034 : INFO : 已處理 160000 篇文章\n",
      "2020-10-06 16:43:48,883 : INFO : 已處理 170000 篇文章\n",
      "2020-10-06 16:44:17,077 : INFO : 已處理 180000 篇文章\n",
      "2020-10-06 16:44:48,480 : INFO : 已處理 190000 篇文章\n",
      "2020-10-06 16:46:49,287 : INFO : 已處理 200000 篇文章\n",
      "2020-10-06 16:47:40,370 : INFO : 已處理 210000 篇文章\n",
      "2020-10-06 16:48:19,219 : INFO : 已處理 220000 篇文章\n",
      "2020-10-06 16:48:52,928 : INFO : 已處理 230000 篇文章\n",
      "2020-10-06 16:49:26,536 : INFO : 已處理 240000 篇文章\n",
      "2020-10-06 16:50:01,910 : INFO : 已處理 250000 篇文章\n",
      "2020-10-06 16:50:40,876 : INFO : 已處理 260000 篇文章\n",
      "2020-10-06 16:51:15,763 : INFO : 已處理 270000 篇文章\n",
      "2020-10-06 16:51:52,411 : INFO : 已處理 280000 篇文章\n",
      "2020-10-06 16:52:24,774 : INFO : 已處理 290000 篇文章\n",
      "2020-10-06 16:52:53,920 : INFO : 已處理 300000 篇文章\n",
      "2020-10-06 16:53:28,089 : INFO : 已處理 310000 篇文章\n",
      "2020-10-06 16:54:01,797 : INFO : 已處理 320000 篇文章\n",
      "2020-10-06 16:54:39,439 : INFO : 已處理 330000 篇文章\n",
      "2020-10-06 16:55:15,972 : INFO : 已處理 340000 篇文章\n",
      "2020-10-06 16:55:54,908 : INFO : 已處理 350000 篇文章\n",
      "2020-10-06 16:56:35,883 : INFO : 已處理 360000 篇文章\n",
      "2020-10-06 16:57:14,188 : INFO : 已處理 370000 篇文章\n",
      "2020-10-06 16:57:31,036 : INFO : finished iterating over Wikipedia corpus of 373840 documents with 86610571 positions (total 3571011 articles, 102049588 positions before pruning articles shorter than 50 words)\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "wiki_corpus = WikiCorpus(\"/home/ubuntu-gpu/Project_Depression/zhwiki-20200920-pages-articles.xml.bz2\", dictionary={})\n",
    "texts_num = 0\n",
    "\n",
    "with open(\"wiki_texts.txt\",'w',encoding='utf-8') as output:\n",
    "    for text in wiki_corpus.get_texts():\n",
    "        output.write(' '.join(text) + '\\n')\n",
    "        texts_num += 1\n",
    "        if texts_num % 10000 == 0:\n",
    "            logging.info(\"已處理 %d 篇文章\" % texts_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!opencc -i wiki_texts.txt -o wiki_zh_tw.txt -c s2tw.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c roccqqck ckiptagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb31157d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb31157d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb30f47d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb30f47d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb30b7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb30b7fd0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb3033e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7cb3033e90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7cb7c88790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7cb7c88790>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17fd24d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17fd24d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17ff3350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17ff3350>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17f89c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17f89c50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17f42b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7c17f42b10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7cb695d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7cb695d1d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b83428050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b83428050>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b8344e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b8344e3d0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b833e2d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b833e2d10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b833fd690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f7b833fd690>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7b82f3b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f7b82f3b0d0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "from ckiptagger import data_utils\n",
    "from ckiptagger import WS, POS, NER\n",
    "ws=WS(\"ckip\")\n",
    "pos=POS(\"ckip\")\n",
    "ner=NER(\"ckip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# jieba custom setting.\n",
    "jieba.set_dictionary('jieba_dict/stopwords.txt')\n",
    "\n",
    "# load stopwords set\n",
    "stopword_set = set()\n",
    "with open('jieba_dict/stopwords.txt','r', encoding='utf-8') as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_set.add(stopword.strip(' \\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('ckip_seg.txt', 'w', encoding='utf-8')\n",
    "with open('wiki_zh_tw.txt', 'r', encoding='utf-8') as content :\n",
    "    for texts_num, line in enumerate(content):\n",
    "        line = line.strip('\\n')\n",
    "        word_s = ws([line])\n",
    "        for word in word_s[0]:\n",
    "            if word not in stopword_set and word != \" \":\n",
    "                output.write(word + ' ')\n",
    "        output.write('\\n')\n",
    "\n",
    "        if (texts_num + 1) % 10000 == 0:\n",
    "                logging.info(\"已完成前 %d 行的斷詞\" % (texts_num + 1))\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\"傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['傅達仁',\n",
       "  '今',\n",
       "  '將',\n",
       "  '執行',\n",
       "  '安樂死',\n",
       "  '，',\n",
       "  '卻',\n",
       "  '突然',\n",
       "  '爆出',\n",
       "  '自己',\n",
       "  '20',\n",
       "  '年',\n",
       "  '前',\n",
       "  '遭',\n",
       "  '緯來',\n",
       "  '體育台',\n",
       "  '封殺',\n",
       "  '，',\n",
       "  '他',\n",
       "  '不',\n",
       "  '懂',\n",
       "  '自己',\n",
       "  '哪裡',\n",
       "  '得罪到',\n",
       "  '電視台',\n",
       "  '。']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_s = ws(sentence_list)\n",
    "word_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_p = pos(word_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_n = ner(word_s, word_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。'\n",
      "傅達仁(Nb)　今(Nd)　將(D)　執行(VC)　安樂死(Na)　，(COMMACATEGORY)　卻(D)　突然(D)　爆出(VJ)　自己(Nh)　20(Neu)　年(Nf)　前(Ng)　遭(P)　緯來(Nb)　體育台(Na)　封殺(VC)　，(COMMACATEGORY)　他(Nh)　不(D)　懂(VK)　自己(Nh)　哪裡(Ncd)　得罪到(VJ)　電視台(Nc)　。(PERIODCATEGORY)　\n",
      "(0, 3, 'PERSON', '傅達仁')\n",
      "(18, 22, 'DATE', '20年前')\n",
      "(23, 28, 'ORG', '緯來體育台')\n",
      "\n",
      "\n",
      "'美國參議院針對今天總統布什所提名的勞工部長趙小蘭展開認可聽證會，預料她將會很順利通過參議院支持，成為該國有史以來第一位的華裔女性內閣成員。'\n",
      "美國(Nc)　參議院(Nc)　針對(P)　今天(Nd)　總統(Na)　布什(Nb)　所(D)　提名(VC)　的(DE)　勞工部長(Na)　趙小蘭(Nb)　展開(VC)　認可(VC)　聽證會(Na)　，(COMMACATEGORY)　預料(VE)　她(Nh)　將(D)　會(D)　很(Dfa)　順利(VH)　通過(VC)　參議院(Nc)　支持(VC)　，(COMMACATEGORY)　成為(VG)　該(Nes)　國(Nc)　有史以來(D)　第一(Neu)　位(Nf)　的(DE)　華裔(Na)　女性(Na)　內閣(Na)　成員(Na)　。(PERIODCATEGORY)　\n",
      "(0, 2, 'GPE', '美國')\n",
      "(2, 5, 'ORG', '參議院')\n",
      "(7, 9, 'DATE', '今天')\n",
      "(11, 13, 'PERSON', '布什')\n",
      "(17, 21, 'ORG', '勞工部長')\n",
      "(21, 24, 'PERSON', '趙小蘭')\n",
      "(42, 45, 'ORG', '參議院')\n",
      "(56, 58, 'ORDINAL', '第一')\n",
      "(60, 62, 'NORP', '華裔')\n",
      "\n",
      "\n",
      "''\n",
      "\n",
      "\n",
      "\n",
      "'土地公有政策?？還是土地婆有政策。.'\n",
      "土地公(Nb)　有(V_2)　政策(Na)　?(QUESTIONCATEGORY)　？(QUESTIONCATEGORY)　還是(Caa)　土地(Na)　婆(Na)　有(V_2)　政策(Na)　。(PERIODCATEGORY)　.(PERIODCATEGORY)　\n",
      "(0, 3, 'PERSON', '土地公')\n",
      "\n",
      "\n",
      "'… 你確定嗎… 不要再騙了……'\n",
      "…(ETCCATEGORY)　 (WHITESPACE)　你(Nh)　確定(VK)　嗎(T)　…(ETCCATEGORY)　 (WHITESPACE)　不要(D)　再(D)　騙(VC)　了(Di)　…(ETCCATEGORY)　…(ETCCATEGORY)　\n",
      "\n",
      "\n",
      "'最多容納59,000個人,或5.9萬人,再多就不行了.這是環評的結論.'\n",
      "最多(VH)　容納(VJ)　59(Neu)　,(COMMACATEGORY)　000(Neu)　個(Nf)　人(Na)　,(COMMACATEGORY)　或(Caa)　5.9萬(Neu)　人(Na)　,(COMMACATEGORY)　再(D)　多(D)　就(D)　不行(VH)　了(T)　.(PERIODCATEGORY)　這(Nep)　是(SHI)　環評(Na)　的(DE)　結論(Na)　.(PERIODCATEGORY)　\n",
      "(4, 6, 'CARDINAL', '59')\n",
      "(7, 10, 'CARDINAL', '000')\n",
      "(14, 18, 'CARDINAL', '5.9萬')\n",
      "\n",
      "\n",
      "'科長說:1,坪數對人數為1:3。2,可以再增加。'\n",
      "科長(Na)　說(VE)　:(COLONCATEGORY)　1(Neu)　,(COMMACATEGORY)　坪數(Na)　對(P)　人數(Na)　為(VG)　1(Neu)　:(COLONCATEGORY)　3(Neu)　。(PERIODCATEGORY)　2(Neu)　,(COMMACATEGORY)　可以(D)　再(D)　增加(VHC)　。(PERIODCATEGORY)　\n",
      "(4, 5, 'CARDINAL', '1')\n",
      "(12, 13, 'CARDINAL', '1')\n",
      "(14, 15, 'CARDINAL', '3')\n",
      "(16, 17, 'CARDINAL', '2')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def combine_wandp(w_list, p_list):\n",
    "    assert len(w_list) == len(p_list)\n",
    "    #\\u3000是空白\n",
    "    for w, p in zip(w_list, p_list):\n",
    "        print ('{}({})'.format(w, p), end='\\u3000')\n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    print (\"'{}'\".format(sentence))\n",
    "    combine_wandp(word_s[i], word_p[i])\n",
    "    print ()\n",
    "    for n in sorted(word_n[i]):\n",
    "        print (n)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainEnv",
   "language": "python",
   "name": "trainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
