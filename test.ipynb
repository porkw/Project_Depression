{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import logging\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieab tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_tokenizer(content):\n",
    "    # load stopwords set\n",
    "    stopword_set = set()\n",
    "    with open('jieba_dict/stopwords.txt','r', encoding='utf-8') as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.add(stopword.strip(' \\n'))\n",
    "\n",
    "    if str(content)=='nan':\n",
    "        return ''\n",
    "    words = jieba.cut(content.replace(' ',''))\n",
    "    return [word for word in words if word not in stopword_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2token(word,w2v_model):\n",
    "\n",
    "    # Retrieve the weights from the model. This is used for initializing the weights\n",
    "    # in a Keras Embedding layer later\n",
    "    w2v_weights = w2v_model.wv.vectors\n",
    "    vocab_size, embedding_size = w2v_weights.shape\n",
    "\n",
    "    try:\n",
    "        return w2v_model.wv.vocab[word].index\n",
    "    # If word is not in index return 0. I realize this means that this\n",
    "    # is the same as the word of index 0 (i.e. most frequent word), but 0s\n",
    "    # will be padded later anyway by the embedding layer (which also\n",
    "    # seems dirty but I couldn't find a better solution right now)\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    \n",
    "def token2word(token):\n",
    "    return w2v_model.wv.index2word[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ckip tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckip_tokenizer(content):\n",
    "#     if str(content)=='nan':\n",
    "#         return ''\n",
    "    word_s = ws([content])\n",
    "    return word_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suicide_predict(text):\n",
    "    model = load_model('lstm_model.h5')\n",
    "\n",
    "    # jieba custom setting.\n",
    "    jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "    text_token = jieba_tokenizer(text)\n",
    "    \n",
    "    \n",
    "    w2v_model = KeyedVectors.load(\"w2v_model.wv\", mmap='r')   \n",
    "    \n",
    "    for i in range(len(text_token)):\n",
    "        text_token[i] = word2token(text_token[i],w2v_model)\n",
    "\n",
    "    text_token = pad_sequences([text_token], maxlen=250, padding='post', value=0)\n",
    "\n",
    "    score = model.predict(text_token)\n",
    "    if score[0][0] > score[0][1]:\n",
    "        results = 0\n",
    "    else:\n",
    "        results = 1\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/ubuntu-gpu/Project_Depression/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u156e2db6fd044c50a8c659fc2a66f9b6.cache\n",
      "Loading model cost 1.295 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/home/ubuntu-gpu/anaconda3/envs/trainEnv/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide_predict(\"也許雨季來臨前就開始了吧什麼都不想做只覺得好累好累考完駕照雖然開心但更覺得鬆了一口氣終於不用在約定時間跟人見面要讀的paper越積越多進度仍是零雖然可以隨便做做但還是想試著做好想試著做好卻一直無法專心讀著下禮拜要上臺介紹的散文集羨慕那些可以有辦法寫的人而我寫的東西永遠詞不達義--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,random_split\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('bert_440.h5')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name      module\n",
      "--------------------\n",
      "bert      embeddings\n",
      "bert      encoder\n",
      "bert      pooler\n",
      "dropout    Dropout(p=0.1, inplace=False)\n",
      "classifier Linear(in_features=768, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "name      module\n",
    "--------------------\"\"\")\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    if name == \"bert\":\n",
    "        for n, _ in module.named_children():\n",
    "            print(\"{:10}{}\".format(name,n) )\n",
    "    else:\n",
    "        print(\"{:10} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"我有時會憂鬱、很想死，認為自己沒有活著的價值了，雖然知道自己沒有勇氣真的去自殺，但心中的壓力與眼角的淚水一直冒出…我有試著和其他人談談，找了位要好高中朋友，她在我心中是特別的存在，是我在心裡方面唯一信賴的人，但隨著高中畢業後大家都有自己的生活圈，也不敢像以前那樣有難受就和她講了，好怕打擾到她；有空時我們還是會約出去吃飯什麼的，但這幾個禮拜可能是我太常和她傳訊息了，所以對我不理不睬的，不知道為什麼…我只是想要找人講話而已，對不起。我算慢熟形的怪人，在大學是個系邊，邊到交不到朋友，也不知道怎麼和他們社交，每次在校園內只有我是孤零零一個人，吃飯也是一樣，什麼都是。身為某宗教信徒，曾經在學長姐的邀約下一起去參加此宗教活動，但後來覺得他們只是想要我去參加而已，有被利用的感覺；我也試著參加學校的各類活動希望交到朋友，當以為自己終於突破交到朋友時，只得到他的背叛而已，在大學的第一段友誼居然是這種下場，不知道還能信任誰了。為了讓自己的社交能力看起來沒那麼可悲，在ig上假裝自己就像其他大學同學一樣有朋友、假裝過著正常的日子，成日當個雙面人，實際的朋友圈只有高中的幾個，可是不知道還能維持到什麼時候，唉… 現在除了在社群軟體當雙面人，也只能滑滑手機、試著尋找新興趣填滿空虛的生活了。雖然還有高中朋友，但能信賴和我聊憂鬱的只有那一位，現在她不理我了，我不知道該怎麼辦？現在好想死，可是又沒勇氣，我真的是廢物，什麼都辦不成，只會哭而已，真的好討厭自己。____________________ 更新____________________這幾天終於鼓起勇氣打電話給另一個高中朋友了，雖然在和她訴苦（求救）時還是有所保留，平時不在他人前流淚的我終究忍不住淚腺；電話中對於我雙面人的事實感到驚訝，在外看似開懷的我居然內心如此脆弱。電話另一頭的那位朋友希望我能好好的找人幫助，並鼓勵我提起勇氣找「她」問出了什麼事。我，終於傳了訊息問了…雖然她說是我想太多了，但仍然滅不了心中全部的焦慮，之後她便不讀不回了…唉 對不起是我太煩人了#有現實生活中認出我的不要來指認，我怕自己崩潰\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "class_names = ['negative', 'positive']\n",
    "\n",
    "encoded_text = tokenizer.encode_plus(\n",
    "    text,\n",
    "    max_length=300,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: 我有時會憂鬱、很想死，認為自己沒有活著的價值了，雖然知道自己沒有勇氣真的去自殺，但心中的壓力與眼角的淚水一直冒出…我有試著和其他人談談，找了位要好高中朋友，她在我心中是特別的存在，是我在心裡方面唯一信賴的人，但隨著高中畢業後大家都有自己的生活圈，也不敢像以前那樣有難受就和她講了，好怕打擾到她；有空時我們還是會約出去吃飯什麼的，但這幾個禮拜可能是我太常和她傳訊息了，所以對我不理不睬的，不知道為什麼…我只是想要找人講話而已，對不起。我算慢熟形的怪人，在大學是個系邊，邊到交不到朋友，也不知道怎麼和他們社交，每次在校園內只有我是孤零零一個人，吃飯也是一樣，什麼都是。身為某宗教信徒，曾經在學長姐的邀約下一起去參加此宗教活動，但後來覺得他們只是想要我去參加而已，有被利用的感覺；我也試著參加學校的各類活動希望交到朋友，當以為自己終於突破交到朋友時，只得到他的背叛而已，在大學的第一段友誼居然是這種下場，不知道還能信任誰了。為了讓自己的社交能力看起來沒那麼可悲，在ig上假裝自己就像其他大學同學一樣有朋友、假裝過著正常的日子，成日當個雙面人，實際的朋友圈只有高中的幾個，可是不知道還能維持到什麼時候，唉… 現在除了在社群軟體當雙面人，也只能滑滑手機、試著尋找新興趣填滿空虛的生活了。雖然還有高中朋友，但能信賴和我聊憂鬱的只有那一位，現在她不理我了，我不知道該怎麼辦？現在好想死，可是又沒勇氣，我真的是廢物，什麼都辦不成，只會哭而已，真的好討厭自己。____________________ 更新____________________這幾天終於鼓起勇氣打電話給另一個高中朋友了，雖然在和她訴苦（求救）時還是有所保留，平時不在他人前流淚的我終究忍不住淚腺；電話中對於我雙面人的事實感到驚訝，在外看似開懷的我居然內心如此脆弱。電話另一頭的那位朋友希望我能好好的找人幫助，並鼓勵我提起勇氣找「她」問出了什麼事。我，終於傳了訊息問了…雖然她說是我想太多了，但仍然滅不了心中全部的焦慮，之後她便不讀不回了…唉 對不起是我太煩人了#有現實生活中認出我的不要來指認，我怕自己崩潰\n",
      "\n",
      "Sentiment  : negative\n"
     ]
    }
   ],
   "source": [
    "input_ids = encoded_text['input_ids'].to(device)\n",
    "attention_mask = encoded_text['attention_mask'].to(device)\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output[0][0], dim=0)\n",
    "\n",
    "print(f'Review text: {text}\\n')\n",
    "print(f'Sentiment  : {class_names[prediction]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "本身就有在身心科就診，離下次回診還有一個多禮拜前幾天因為學校有事情要忙，所以那幾天比較累。以前累的時候不會有感覺到情緒起伏很大或異常（就是10分鐘內可以交替亢奮/低落）最近這幾天一直處於嗜睡狀態，一天"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
